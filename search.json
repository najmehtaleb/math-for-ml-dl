[
  {
    "objectID": "01-linear-algebra/02-matrices.html",
    "href": "01-linear-algebra/02-matrices.html",
    "title": "Matrices",
    "section": "",
    "text": "from numpy import inf\nfrom numpy import array\nfrom numpy import identity\nfrom numpy import trace\nfrom numpy import count_nonzero\nfrom numpy import tensordot\nfrom numpy import tril, triu, diag\nfrom numpy.linalg import norm, inv, det, matrix_rank\nfrom scipy.sparse import csr_matrix"
  },
  {
    "objectID": "01-linear-algebra/02-matrices.html#vectors-and-vector-arithmetic",
    "href": "01-linear-algebra/02-matrices.html#vectors-and-vector-arithmetic",
    "title": "Matrices",
    "section": "Vectors and Vector Arithmetic",
    "text": "Vectors and Vector Arithmetic\nDefining a Vector\n\nvector = array([1,2,3])\nprint(vector)\n\n[1 2 3]\n\n\n\nVector Arithmetic\nVector Addition\n\na = array([1,2,3])\nprint(a)\n\n[1 2 3]\n\n\n\nb = array([4,5,6])\nprint(b)\n\n[4 5 6]\n\n\n\nc = a + b\nprint(c)\n\n[5 7 9]\n\n\nVector Subtraction\n\na = array([1,2,3])\nprint(a)\n\n[1 2 3]\n\n\n\nb = array([0.5,0.5,0.5])\nprint(b)\n\n[0.5 0.5 0.5]\n\n\n\nc = a - b\nprint(c)\n\n[0.5 1.5 2.5]\n\n\nVector Multiplication\n\na = array([1,2,3])\nprint(a)\n\n[1 2 3]\n\n\n\nb = array([1,2,3])\nprint(b)\n\n[1 2 3]\n\n\n\nc = a*b\nprint(c)\n\n[1 4 9]\n\n\nVector Division\n\na = array([1,2,3])\nprint(a)\n\n[1 2 3]\n\n\n\nb = array([1,2,3])\nprint(b)\n\n[1 2 3]\n\n\n\nc = a/b\nprint(c)\n\n[1. 1. 1.]\n\n\n\n\nVector Dot Product\n\na = array([1,2,3])\nprint(a)\n\n[1 2 3]\n\n\n\nb = array([1,2,3])\nprint(b)\n\n[1 2 3]\n\n\n\nc = a.dot(b)\nprint(c)\n\n14\n\n\n\n\nVector-Scalar Multiplication\n\na = array([1,2,3])\nprint(a)\n\n[1 2 3]\n\n\n\nb = 0.5\nprint(b)\n\n0.5\n\n\n\nc = b*a\nprint(c)\n\n[0.5 1.  1.5]"
  },
  {
    "objectID": "01-linear-algebra/02-matrices.html#vector-norms",
    "href": "01-linear-algebra/02-matrices.html#vector-norms",
    "title": "Matrices",
    "section": "Vector Norms",
    "text": "Vector Norms\n\na = array([1,2,3])\nprint(a)\n\n[1 2 3]\n\n\nVector L1 Norm\n\nl1 = norm(a, 1)\nprint(l1)\n\n6.0\n\n\nVector L2 Norm\n\nl2 = norm(a)\nprint(l2)\n\n3.7416573867739413\n\n\nVector Max Norm\n\nmaxnorm = norm(a,inf)\nprint(maxnorm)\n\n3.0"
  },
  {
    "objectID": "01-linear-algebra/02-matrices.html#matrices-and-matrix-arithmetic",
    "href": "01-linear-algebra/02-matrices.html#matrices-and-matrix-arithmetic",
    "title": "Matrices",
    "section": "Matrices and Matrix Arithmetic",
    "text": "Matrices and Matrix Arithmetic\nDefining a Matrix\n\nA = array([[1,2,3],\n          [4,5,6]])\nprint(A)\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nMatrix Arithmetic\n\nA = array([[1,2,3],\n         [4,5,6]])\nprint(A)\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nB = array([[1,2,3],\n          [4,5,6]])\nprint(B)\n\n[[1 2 3]\n [4 5 6]]\n\n\nMatrix Addition\n\nC = A + B\nprint(C)\n\n[[ 2  4  6]\n [ 8 10 12]]\n\n\nMatrix Subtraction\n\nC = A - B\nprint(C)\n\n[[0 0 0]\n [0 0 0]]\n\n\nMatrix Multiplication (Hadamard Product)\n\nC = A *B\nprint(C)\n\n[[ 1  4  9]\n [16 25 36]]\n\n\nMatrix Division\n\nC = A / B\nprint(C)\n\n[[1. 1. 1.]\n [1. 1. 1.]]\n\n\n\n\nMatrix-Matrix Multiplication\n\nA = array([\n    [1,2],\n    [3,4],\n    [5,6]])\nprint(A)\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nB = array([\n    [1,2],\n    [3,4]])\nprint(B)\n\n[[1 2]\n [3 4]]\n\n\n\nC = A.dot(B)\nprint(C)\n\n[[ 7 10]\n [15 22]\n [23 34]]\n\n\n\nD = A @ B\nprint(D)\n\n[[ 7 10]\n [15 22]\n [23 34]]\n\n\n\n\nMatrix-Vector Multiplication\n\nA = array([\n    [1,2],\n    [3,4],\n    [5,6]])\nprint(A)\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nb = array([0.5, 0.5])\nprint(b)\n\n[0.5 0.5]\n\n\n\nC = A.dot(b)\nprint(C)\n\n[1.5 3.5 5.5]\n\n\n\n\nMatrix-Scalar Multiplication\n\nA = array([\n    [1,2],\n    [3,4],\n    [5,6]])\nprint(A)\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nb = 0.5\nprint(b)\n\n0.5\n\n\n\nC = A*b\nprint(C)\n\n[[0.5 1. ]\n [1.5 2. ]\n [2.5 3. ]]"
  },
  {
    "objectID": "01-linear-algebra/02-matrices.html#types-of-matrices",
    "href": "01-linear-algebra/02-matrices.html#types-of-matrices",
    "title": "Matrices",
    "section": "Types of Matrices",
    "text": "Types of Matrices\nSquare Matrix\nSymmetric Matrix\nTriangular Matrix\n\nM = array([\n    [1,2,3],\n    [1,2,3],\n    [1,2,3]])\nprint(M)\n\n[[1 2 3]\n [1 2 3]\n [1 2 3]]\n\n\n\nlower = tril(M)\nprint(lower)\n\n[[1 0 0]\n [1 2 0]\n [1 2 3]]\n\n\n\nupper = triu(M)\nprint(upper)\n\n[[1 2 3]\n [0 2 3]\n [0 0 3]]\n\n\nDiagonal Matrix\n\nM = array([\n    [1,2,3],\n    [1,2,3],\n    [1,2,3]])\nprint(M)\n\n[[1 2 3]\n [1 2 3]\n [1 2 3]]\n\n\n\nd = diag(M)\nprint(d)\n\n[1 2 3]\n\n\n\nD = diag(d)\nprint(D)\n\n[[1 0 0]\n [0 2 0]\n [0 0 3]]\n\n\nIdentity Matrix\n\nI = identity(3)\nprint(I)\n\n[[1. 0. 0.]\n [0. 1. 0.]\n [0. 0. 1.]]\n\n\nOrthogonal Matrix\n\nQ = array([\n    [1,0],\n    [0,-1]])\nprint(Q)\n\n[[ 1  0]\n [ 0 -1]]\n\n\n\nV = inv(Q)\nprint(V)\n\n[[ 1.  0.]\n [-0. -1.]]\n\n\n\nprint(Q.T)\n\n[[ 1  0]\n [ 0 -1]]\n\n\n\nI = Q.dot(Q.T)\nprint(I)\n\n[[1 0]\n [0 1]]"
  },
  {
    "objectID": "01-linear-algebra/02-matrices.html#matrix-operations",
    "href": "01-linear-algebra/02-matrices.html#matrix-operations",
    "title": "Matrices",
    "section": "Matrix Operations",
    "text": "Matrix Operations\nTranspose\n\nA = array([\n    [1,2],\n    [3,4],\n    [5,6]])\nprint(A)\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nC = A.T\nprint(C)\n\n[[1 3 5]\n [2 4 6]]\n\n\nInverse\n\nA = array([\n    [1.0, 2.0],\n    [3.0, 4.0]])\nprint(A)\n\n[[1. 2.]\n [3. 4.]]\n\n\n\nB = inv(A)\nprint(B)\n\n[[-2.   1. ]\n [ 1.5 -0.5]]\n\n\n\nI = A.dot(B)\nprint(I)\n\n[[1.0000000e+00 0.0000000e+00]\n [8.8817842e-16 1.0000000e+00]]\n\n\nTrace\n\nA = array([\n    [1,2,3],\n    [4,5,6],\n    [7,8,9]])\nprint(A)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n\n\n\nB = trace(A)\nprint(B)\n\n15\n\n\nDeterminant\n\nA = array([\n    [1,2,3],\n    [4,5,6],\n    [7,8,99]])\nprint(A)\n\n[[ 1  2  3]\n [ 4  5  6]\n [ 7  8 99]]\n\n\n\nB = det(A)\nprint(B)\n\n-269.99999999999983\n\n\nRank\n\nv1 = array([1,2,3])\nprint(v1)\n\n[1 2 3]\n\n\n\nprint(matrix_rank(v1))\n\n1\n\n\n\nv2 = array([0,0,0,0,0])\nprint(v2)\n\n[0 0 0 0 0]\n\n\n\nprint(matrix_rank(v2))\n\n0\n\n\n\nM0 = array([\n    [0,0],\n    [0,0]])\nprint(M0)\n\n[[0 0]\n [0 0]]\n\n\n\nprint(matrix_rank(M0))\n\n0\n\n\n\nM1 = array([\n    [1,2],\n    [1,2]])\nprint(M1)\n\n[[1 2]\n [1 2]]\n\n\n\nprint(matrix_rank(M1))\n\n1\n\n\n\nM2 = array([\n    [1,2],\n    [3,4]])\nprint(M2)\n\n[[1 2]\n [3 4]]\n\n\n\nprint(matrix_rank(M2))\n\n2"
  },
  {
    "objectID": "01-linear-algebra/02-matrices.html#sparse-matrices",
    "href": "01-linear-algebra/02-matrices.html#sparse-matrices",
    "title": "Matrices",
    "section": "Sparse Matrices",
    "text": "Sparse Matrices\nSparse Matrices in Python\n\nA = array([\n    [1,0,0,1,0,0],\n    [0,0,2,0,0,1],\n    [0,0,0,2,0,0]])\nprint(A)\n\n[[1 0 0 1 0 0]\n [0 0 2 0 0 1]\n [0 0 0 2 0 0]]\n\n\n\nS = csr_matrix(A)\nprint(S)\n\n  (0, 0)    1\n  (0, 3)    1\n  (1, 2)    2\n  (1, 5)    1\n  (2, 3)    2\n\n\n\nB = S.todense()\nprint(B)\n\n[[1 0 0 1 0 0]\n [0 0 2 0 0 1]\n [0 0 0 2 0 0]]\n\n\n\nsparsity = 1.0 - count_nonzero(A) / A.size\nprint(sparsity)\n\n0.7222222222222222"
  },
  {
    "objectID": "01-linear-algebra/02-matrices.html#tensors-and-tensor-arithmetic",
    "href": "01-linear-algebra/02-matrices.html#tensors-and-tensor-arithmetic",
    "title": "Matrices",
    "section": "Tensors and Tensor Arithmetic",
    "text": "Tensors and Tensor Arithmetic\n\nTensors in Python\n\nT = array([\n    [[1,2,3], [4,5,6], [7,8,9]],\n    [[11,12,13], [14,15,16], [17,18,19]],\n    [[21,22,23], [24,25,26], [27,28,29]]])\nprint(T)\n\n[[[ 1  2  3]\n  [ 4  5  6]\n  [ 7  8  9]]\n\n [[11 12 13]\n  [14 15 16]\n  [17 18 19]]\n\n [[21 22 23]\n  [24 25 26]\n  [27 28 29]]]\n\n\n\nprint(T.shape)\n\n(3, 3, 3)\n\n\n\n\nTensor Arithmetic\nTensor Addition\n\nA = array([\n    [[1,2,3], [4,5,6], [7,8,9]],\n    [[11,12,13], [14,15,16], [17,18,19]],\n    [[21,22,23], [24,25,26], [27,28,29]]])\n\nB = array([\n    [[1,2,3], [4,5,6], [7,8,9]],\n    [[11,12,13], [14,15,16], [17,18,19]],\n    [[21,22,23], [24,25,26], [27,28,29]]])\n\nC = A + B\nprint(C)\n\n[[[ 2  4  6]\n  [ 8 10 12]\n  [14 16 18]]\n\n [[22 24 26]\n  [28 30 32]\n  [34 36 38]]\n\n [[42 44 46]\n  [48 50 52]\n  [54 56 58]]]\n\n\nTensor Subtraction\n\nA = array([\n    [[1,2,3], [4,5,6], [7,8,9]],\n    [[11,12,13], [14,15,16], [17,18,19]],\n    [[21,22,23], [24,25,26], [27,28,29]]])\n\nB = array([\n    [[1,2,3], [4,5,6], [7,8,9]],\n    [[11,12,13], [14,15,16], [17,18,19]],\n    [[21,22,23], [24,25,26], [27,28,29]]])\n\nC = A - B\nprint(C)\n\n[[[0 0 0]\n  [0 0 0]\n  [0 0 0]]\n\n [[0 0 0]\n  [0 0 0]\n  [0 0 0]]\n\n [[0 0 0]\n  [0 0 0]\n  [0 0 0]]]\n\n\nTensor Hadamard Product\n\nA = array([\n    [[1,2,3], [4,5,6], [7,8,9]],\n    [[11,12,13], [14,15,16], [17,18,19]],\n    [[21,22,23], [24,25,26], [27,28,29]]])\n\nB = array([\n    [[1,2,3], [4,5,6], [7,8,9]],\n    [[11,12,13], [14,15,16], [17,18,19]],\n    [[21,22,23], [24,25,26], [27,28,29]]])\n\nC = A * B\nprint(C)\n\n[[[  1   4   9]\n  [ 16  25  36]\n  [ 49  64  81]]\n\n [[121 144 169]\n  [196 225 256]\n  [289 324 361]]\n\n [[441 484 529]\n  [576 625 676]\n  [729 784 841]]]\n\n\nTensor Division\n\nA = array([\n    [[1,2,3], [4,5,6], [7,8,9]],\n    [[11,12,13], [14,15,16], [17,18,19]],\n    [[21,22,23], [24,25,26], [27,28,29]]])\n\nB = array([\n    [[1,2,3], [4,5,6], [7,8,9]],\n    [[11,12,13], [14,15,16], [17,18,19]],\n    [[21,22,23], [24,25,26], [27,28,29]]])\n\nC = A / B\nprint(C)\n\n[[[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]\n\n [[1. 1. 1.]\n  [1. 1. 1.]\n  [1. 1. 1.]]]\n\n\n\n\nTensor Product\n\nA = array([1,2])\nB = array([3,4])\n\n\nC = tensordot(A, B, axes=0)\nprint(C)\n\n[[3 4]\n [6 8]]"
  },
  {
    "objectID": "01-linear-algebra/03-factorization.html",
    "href": "01-linear-algebra/03-factorization.html",
    "title": "Factorization",
    "section": "",
    "text": "from numpy import diag\nfrom numpy import zeros"
  },
  {
    "objectID": "01-linear-algebra/03-factorization.html#matrix-decompositions",
    "href": "01-linear-algebra/03-factorization.html#matrix-decompositions",
    "title": "Factorization",
    "section": "Matrix Decompositions",
    "text": "Matrix Decompositions\nMany complex matrix operations cannot be solved efficiently or with stability using the limited precision of computers. Matrix decompositions are methods that reduce a matrix into constituent parts that make it easier to calculate more complex matrix operations. Matrix decomposition methods, also called matrix factorization methods, are a foundation of linear algebra in computers, even for basic operations such as solving systems of linear equations, calculating the inverse, and calculating the determinant of a matrix. In this tutorial, you will discover matrix decompositions and how to calculate them in Python.\n\nWhat is a Matrix Decomposition\nA matrix decomposition is a way of reducing a matrix into its constituent parts. It is an approach that can simplify more complex matrix operations that can be performed on the decomposed matrix rather than on the original matrix itself. A common analogy for matrix decomposition is the factoring of numbers, such as the factoring of 10 into 2 × 5. For this reason, matrix decomposition is also called matrix factorization. Like factoring real values, there are many ways to decompose a matrix, hence there are a range of different matrix decomposition techniques. Two simple and widely used matrix decomposition methods are the LU matrix decomposition and the QR matrix decomposition. Next, we will take a closer look at each of these methods.\n\n\nLU Decomposition\n\nfrom numpy import array\nfrom scipy.linalg import lu\n\n\nA = array([\n    [1,2,3],\n    [4,5,6],\n    [7,8,9]])\nprint(A)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n\n\n\nP, L, U = lu(A)\n\n\nprint(P)\n\n[[0. 1. 0.]\n [0. 0. 1.]\n [1. 0. 0.]]\n\n\n\nprint(L)\n\n[[1.         0.         0.        ]\n [0.14285714 1.         0.        ]\n [0.57142857 0.5        1.        ]]\n\n\n\nprint(U)\n\n[[7.         8.         9.        ]\n [0.         0.85714286 1.71428571]\n [0.         0.         0.        ]]\n\n\n\nB = P.dot(L).dot(U)\nprint(B)\n\n[[1. 2. 3.]\n [4. 5. 6.]\n [7. 8. 9.]]\n\n\n\n\nQR Decomposition\n\nfrom numpy import array\nfrom scipy.linalg import qr\n\n\nA = array([\n    [1,2],\n    [3,4],\n    [5,6]])\nprint(A)\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nQ, R = qr(A)\n\n\nprint(Q)\n\n[[-0.16903085  0.89708523  0.40824829]\n [-0.50709255  0.27602622 -0.81649658]\n [-0.84515425 -0.34503278  0.40824829]]\n\n\n\nprint(R)\n\n[[-5.91607978 -7.43735744]\n [ 0.          0.82807867]\n [ 0.          0.        ]]\n\n\n\nB = Q.dot(R)\nprint(B)\n\n[[1. 2.]\n [3. 4.]\n [5. 6.]]\n\n\n\n\nCholesky Decomposition\n\nfrom numpy import array\nfrom numpy.linalg import cholesky\n\n\nA = array([\n    [2,1,1],\n    [1,2,1],\n    [1,1,2]])\nprint(A)\n\n[[2 1 1]\n [1 2 1]\n [1 1 2]]\n\n\n\nL = cholesky(A)\nprint(L)\n\n[[1.41421356 0.         0.        ]\n [0.70710678 1.22474487 0.        ]\n [0.70710678 0.40824829 1.15470054]]\n\n\n\nB = L.dot(L.T)\nprint(B)\n\n[[2. 1. 1.]\n [1. 2. 1.]\n [1. 1. 2.]]"
  },
  {
    "objectID": "01-linear-algebra/03-factorization.html#eigendecomposition",
    "href": "01-linear-algebra/03-factorization.html#eigendecomposition",
    "title": "Factorization",
    "section": "Eigendecomposition",
    "text": "Eigendecomposition\nPerhaps the most used type of matrix decomposition is the eigendecomposition that decomposes a matrix into eigenvectors and eigenvalues. This decomposition also plays a role in methods used in machine learning, such as in the Principal Component Analysis method or PCA.\n\nEigendecomposition of a Matrix\n\n\nEigenvectors and Eigenvalues\n\n\nCalculation of Eigendecomposition\n\nfrom numpy import array\nfrom numpy.linalg import eig\n\n\nA = array([\n    [1,2,3],\n    [4,5,6],\n    [7,8,9]])\nprint(A)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n\n\n\nvalues, vectors = eig(A)\n\n\nprint(values)\n\n[ 1.61168440e+01 -1.11684397e+00 -1.30367773e-15]\n\n\n\nprint(vectors)\n\n[[-0.23197069 -0.78583024  0.40824829]\n [-0.52532209 -0.08675134 -0.81649658]\n [-0.8186735   0.61232756  0.40824829]]\n\n\n\n\nConfirm an Eigenvector and Eigenvalue\n\nfrom numpy import array\nfrom numpy.linalg import eig\n\n\nA = array([\n    [1,2,3],\n    [4,5,6],\n    [7,8,9]])\nprint(A)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n\n\n\nvalues, vectors = eig(A)\n\n\nB = A.dot(vectors[:,0])\nprint(B)\n\n[ -3.73863537  -8.46653421 -13.19443305]\n\n\n\nC = vectors[:,0] * values[0]\nprint(C)\n\n[ -3.73863537  -8.46653421 -13.19443305]\n\n\n\n\nReconstruct Matrix\n\nfrom numpy import array, diag\nfrom numpy.linalg import eig, inv\n\n\nA = array([\n    [1,2,3],\n    [4,5,6],\n    [7,8,9]])\nprint(A)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n\n\n\nvalues, vectors = eig(A)\n\n\nQ = vectors\n\n\nR = inv(Q)\n\n\nL = diag(values)\n\n\nB = Q.dot(L).dot(R)\nprint(B)\n\n[[1. 2. 3.]\n [4. 5. 6.]\n [7. 8. 9.]]"
  },
  {
    "objectID": "01-linear-algebra/03-factorization.html#singular-value-decomposition",
    "href": "01-linear-algebra/03-factorization.html#singular-value-decomposition",
    "title": "Factorization",
    "section": "Singular Value Decomposition",
    "text": "Singular Value Decomposition\n\nCalculate Singular-Value Decomposition\n\nfrom numpy import array\nfrom numpy.linalg import svd\n\n\nA = array([\n    [1,2],\n    [3,4],\n    [5,6]])\nprint(A)\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nU, s, VT = svd(A)\n\n\nprint(U)\n\n[[-0.2298477   0.88346102  0.40824829]\n [-0.52474482  0.24078249 -0.81649658]\n [-0.81964194 -0.40189603  0.40824829]]\n\n\n\nprint(s)\n\n[9.52551809 0.51430058]\n\n\n\nprint(VT)\n\n[[-0.61962948 -0.78489445]\n [-0.78489445  0.61962948]]\n\n\n\n\nReconstruct Matrix\n\nA = array([\n    [1,2],\n    [3,4],\n    [5,6]])\nprint(A)\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nU, s, VT = svd(A)\n\n\nSigma = zeros((A.shape[0], A.shape[1]))\n\n\nSigma[:A.shape[1], :A.shape[1]] = diag(s)\n\n\nB = U.dot(Sigma.dot(VT))\nprint(B)\n\n[[1. 2.]\n [3. 4.]\n [5. 6.]]\n\n\n\nA = array([\n    [1,2,3],\n    [4,5,6],\n    [7,8,9]])\nprint(A)\n\n[[1 2 3]\n [4 5 6]\n [7 8 9]]\n\n\n\nU, s , VT = svd(A)\n\n\nSigma = diag(s)\n\n\nB = U.dot(Sigma.dot(VT))\nprint(B)\n\n[[1. 2. 3.]\n [4. 5. 6.]\n [7. 8. 9.]]\n\n\n\n\nPseudoinverse\n\nfrom numpy import array\nfrom numpy.linalg import pinv\n\n\nA = array([\n    [0.1, 0.2],\n    [0.3, 0.4],\n    [0.5, 0.6],\n    [0.7, 0.8]])\nprint(A)\n\n[[0.1 0.2]\n [0.3 0.4]\n [0.5 0.6]\n [0.7 0.8]]\n\n\n\nB = pinv(A)\nprint(B)\n\n[[-1.00000000e+01 -5.00000000e+00  1.42385628e-14  5.00000000e+00]\n [ 8.50000000e+00  4.50000000e+00  5.00000000e-01 -3.50000000e+00]]\n\n\n\nU, s, VT = svd(A)\n\n\nd = 1.0 / s\n\n\nD = zeros(A.shape)\n\n\nD[:A.shape[1], :A.shape[1]] = diag(d)\n\n\nB = VT.T.dot(D.T).dot(U.T)\nprint(B)\n\n[[-1.00000000e+01 -5.00000000e+00  1.42578328e-14  5.00000000e+00]\n [ 8.50000000e+00  4.50000000e+00  5.00000000e-01 -3.50000000e+00]]\n\n\n\n\nDimensionality Reduction\n\nA = array([\n[1,2,3,4,5,6,7,8,9,10],\n[11,12,13,14,15,16,17,18,19,20],\n[21,22,23,24,25,26,27,28,29,30]])\nprint(A)\n\n[[ 1  2  3  4  5  6  7  8  9 10]\n [11 12 13 14 15 16 17 18 19 20]\n [21 22 23 24 25 26 27 28 29 30]]\n\n\n\nU, s, VT = svd(A)\n\n\nSigma = zeros((A.shape[0], A.shape[1]))\n\n\nSigma[:A.shape[0], :A.shape[0]] = diag(s)\n\n\nn_elemnts = 2\n\n\nSigma = Sigma[:, :n_elemnts]\n\n\nVT = VT[:n_elemnts, :]\n\n\nB = U.dot(Sigma.dot(VT))\nprint(B)\n\n[[ 1.  2.  3.  4.  5.  6.  7.  8.  9. 10.]\n [11. 12. 13. 14. 15. 16. 17. 18. 19. 20.]\n [21. 22. 23. 24. 25. 26. 27. 28. 29. 30.]]\n\n\n\nT = U.dot(Sigma)\nprint(T)\n\n[[-18.52157747   6.47697214]\n [-49.81310011   1.91182038]\n [-81.10462276  -2.65333138]]\n\n\n\nT = A.dot(VT.T)\nprint(T)\n\n[[-18.52157747   6.47697214]\n [-49.81310011   1.91182038]\n [-81.10462276  -2.65333138]]"
  },
  {
    "objectID": "01-linear-algebra/04-statistics.html",
    "href": "01-linear-algebra/04-statistics.html",
    "title": "Statistics",
    "section": "",
    "text": "from numpy import array\nfrom numpy import mean, var, std, cov, corrcoef\nfrom numpy.linalg import eig, inv, pinv, qr, lstsq\nfrom sklearn.decomposition import PCA\nfrom matplotlib import pyplot"
  },
  {
    "objectID": "01-linear-algebra/04-statistics.html#introduction-to-multivariate-statistics",
    "href": "01-linear-algebra/04-statistics.html#introduction-to-multivariate-statistics",
    "title": "Statistics",
    "section": "Introduction to Multivariate Statistics",
    "text": "Introduction to Multivariate Statistics\n\nExpected Value and Mean\n\nv = array([1,2,3,4,5,6])\nprint(v)\n\n[1 2 3 4 5 6]\n\n\n\nresult = mean(v)\nprint(result)\n\n3.5\n\n\n\nM = array([\n    [1,2,3,4,5,6],\n    [1,2,3,4,5,6]])\nprint(M)\n\n[[1 2 3 4 5 6]\n [1 2 3 4 5 6]]\n\n\n\ncol_mean = mean(M, axis=0)\nprint(col_mean)\n\n[1. 2. 3. 4. 5. 6.]\n\n\n\nrow_mean = mean(M, axis=1)\nprint(row_mean)\n\n[3.5 3.5]\n\n\n\n\nVariance and Standard Deviation\n\nv = array([1,2,3,4,5,6])\nprint(v)\n\n[1 2 3 4 5 6]\n\n\n\nresult = var(v, ddof=1)\nprint(result)\n\n3.5\n\n\n\nM = array([\n    [1,2,3,4,5,6],\n    [1,2,3,4,5,6]])\nprint(M)\n\n[[1 2 3 4 5 6]\n [1 2 3 4 5 6]]\n\n\n\ncol_var = var(M, ddof=1, axis=0)\nprint(col_var)\n\n[0. 0. 0. 0. 0. 0.]\n\n\n\nrow_var = var(M, ddof=1, axis=1)\nprint(row_var)\n\n[3.5 3.5]\n\n\n\ncol_std = std(M, ddof=1, axis=0)\nprint(col_std)\n\n[0. 0. 0. 0. 0. 0.]\n\n\n\nrow_std = std(M, ddof=1, axis=1)\nprint(row_std)\n\n[1.87082869 1.87082869]\n\n\n\n\nCovariance and Correlation\n\nx = array([1,2,3,4,5,6,7,8,9])\nprint(x)\n\n[1 2 3 4 5 6 7 8 9]\n\n\n\ny = array([9,8,7,6,5,4,3,2,1])\nprint(y)\n\n[9 8 7 6 5 4 3 2 1]\n\n\n\nSigma = cov(x,y)[0,1]\nprint(Sigma)\n\n-7.5\n\n\n\ncorr = corrcoef(x,y)[0,1]\nprint(corr)\n\n-1.0\n\n\n\n\nCovariance Matrix\n\nX = array([\n    [1, 5, 8],\n    [3, 5, 11],\n    [2, 4, 9],\n    [3, 6, 10],\n    [1, 5, 10]])\nprint(X)\n\n[[ 1  5  8]\n [ 3  5 11]\n [ 2  4  9]\n [ 3  6 10]\n [ 1  5 10]]\n\n\n\nSigma = cov(X.T)\nprint(Sigma)\n\n[[1.   0.25 0.75]\n [0.25 0.5  0.25]\n [0.75 0.25 1.3 ]]"
  },
  {
    "objectID": "01-linear-algebra/04-statistics.html#principal-component-analysis",
    "href": "01-linear-algebra/04-statistics.html#principal-component-analysis",
    "title": "Statistics",
    "section": "Principal Component Analysis",
    "text": "Principal Component Analysis\n\nCalculate Principal Component Analysis\n\nA = array([\n    [1,2],\n    [3,4],\n    [5,6]])\nprint(A)\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\nM = mean(A.T, axis=1)\n\n\nC = A - M\n\n\nV = cov(C.T)\n\n\nvalues, vectors = eig(V)\n\n\nprint(vectors)\n\n[[ 0.70710678 -0.70710678]\n [ 0.70710678  0.70710678]]\n\n\n\nprint(values)\n\n[8. 0.]\n\n\n\nP = vectors.T.dot(C.T)\nprint(P.T)\n\n[[-2.82842712  0.        ]\n [ 0.          0.        ]\n [ 2.82842712  0.        ]]\n\n\n\n\nPrincipal Component Analysis in scikit-learn\n\nA = array([\n    [1,2],\n    [3,4],\n    [5,6]])\nprint(A)\n\n[[1 2]\n [3 4]\n [5 6]]\n\n\n\npca = PCA(2)\n\n\npca.fit(A)\n\nPCA(n_components=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.PCAPCA(n_components=2)\n\n\n\nprint(pca.components_)\n\n[[ 0.70710678  0.70710678]\n [-0.70710678  0.70710678]]\n\n\n\nprint(pca.explained_variance_)\n\n[8. 0.]\n\n\n\nB = pca.transform(A)\nprint(B)\n\n[[-2.82842712e+00 -2.22044605e-16]\n [ 0.00000000e+00  0.00000000e+00]\n [ 2.82842712e+00  2.22044605e-16]]"
  },
  {
    "objectID": "01-linear-algebra/04-statistics.html#linear-regression",
    "href": "01-linear-algebra/04-statistics.html#linear-regression",
    "title": "Statistics",
    "section": "Linear Regression",
    "text": "Linear Regression\n\ndata = array([\n    [0.05, 0.12],\n    [0.18, 0.22],\n    [0.31, 0.35],\n    [0.42, 0.38],\n    [0.5, 0.49]])\nprint(data)\n\n[[0.05 0.12]\n [0.18 0.22]\n [0.31 0.35]\n [0.42 0.38]\n [0.5  0.49]]\n\n\n\nX, y = data[:, 0], data[:,1]\nX = X.reshape(len(X), 1)\n\n\nLinear Regression Dataset\n\npyplot.scatter(X, y)\npyplot.show()\n\n\n\n\n\n\nSolve via Inverse\n\nb = inv(X.T.dot(X)).dot(X.T).dot(y)\nprint(b)\n\n[1.00233226]\n\n\n\nyhat = X.dot(b)\n\n\npyplot.scatter(X,y)\npyplot.plot(X, yhat, color='red')\npyplot.show()\n\n\n\n\n\n\nSolve via QR Decomposition\n\nQ, R = qr(X)\nb = inv(R).dot(Q.T).dot(y)\nprint(b)\n\n[1.00233226]\n\n\n\nyhat = X.dot(b)\n\n\npyplot.scatter(X, y)\npyplot.plot(X, yhat, color='red')\npyplot.show()\n\n\n\n\n\n\nSolve via SVD and Pseudoinverse\n\nb = pinv(X).dot(y)\nprint(b)\n\n[1.00233226]\n\n\n\nyhat = X.dot(b)\n\n\npyplot.scatter(X, y)\npyplot.plot(X, yhat, color='red')\npyplot.show()\n\n\n\n\n\n\nSolve via Convenience Function\n\nb, residuals, rank, s = lstsq(X, y)\nprint(b)\n\n[1.00233226]\n\n\n/tmp/ipykernel_21840/4284049170.py:1: FutureWarning: `rcond` parameter will change to the default of machine precision times ``max(M, N)`` where M and N are the input matrix dimensions.\nTo use the future default and silence this warning we advise to pass `rcond=None`, to keep using the old, explicitly pass `rcond=-1`.\n  b, residuals, rank, s = lstsq(X, y)\n\n\n\nyhat = X.dot(b)\n\n\npyplot.scatter(X, y)\npyplot.plot(X, yhat, color='red')\npyplot.show()"
  },
  {
    "objectID": "01-linear-algebra/01-numpy.html",
    "href": "01-linear-algebra/01-numpy.html",
    "title": "NumPy",
    "section": "",
    "text": "from numpy import array\nfrom numpy import empty\nfrom numpy import zeros\nfrom numpy import ones\nfrom numpy import vstack\nfrom numpy import hstack"
  },
  {
    "objectID": "01-linear-algebra/01-numpy.html#introduction-to-numpy-arrays",
    "href": "01-linear-algebra/01-numpy.html#introduction-to-numpy-arrays",
    "title": "NumPy",
    "section": "Introduction to NumPy Arrays",
    "text": "Introduction to NumPy Arrays\n\nNumPy N-dimensional Array\n\nmy_list = [1.0, 2.0, 3.0]\n\n\nmy_array = array(my_list)\n\n\ntype(my_array)\n\nnumpy.ndarray\n\n\n\nprint(my_array)\n\n[1. 2. 3.]\n\n\n\nprint(my_array.shape, my_array.dtype)\n\n(3,) float64\n\n\n\n\nFunctions to Create Arrays\nEmpty\n\nmy_array = empty([3,3])\nmy_array\n\narray([[6.94676088e-310, 6.94676088e-310, 0.00000000e+000],\n       [0.00000000e+000, 0.00000000e+000, 0.00000000e+000],\n       [1.23075756e-312, 2.42092166e-322, 6.94676088e-310]])\n\n\nZeros\n\nmy_array = zeros([2,5])\nmy_array\n\narray([[0., 0., 0., 0., 0.],\n       [0., 0., 0., 0., 0.]])\n\n\nOnes\n\nmy_array = ones([4,2])\nmy_array\n\narray([[1., 1.],\n       [1., 1.],\n       [1., 1.],\n       [1., 1.]])\n\n\n\n\nCombining Arrays\nVertical Stack\n\na1 = array([1,2,3])\nprint(a1)\n\n[1 2 3]\n\n\n\na2 = array([4,5,6])\nprint(a2)\n\n[4 5 6]\n\n\n\na3 = vstack((a1,a2))\nprint(a3)\n\n[[1 2 3]\n [4 5 6]]\n\n\n\nprint(a3.shape)\n\n(2, 3)\n\n\nHorizontal Stack\n\na1 = array([1,2,3])\n\n\na2 = array([4,5,6])\n\n\na3 = hstack((a1,a2))\nprint(a3)\n\n[1 2 3 4 5 6]\n\n\n\nprint(a3.shape)\n\n(6,)"
  },
  {
    "objectID": "01-linear-algebra/01-numpy.html#index-slice-and-reshape-numpy-arrays",
    "href": "01-linear-algebra/01-numpy.html#index-slice-and-reshape-numpy-arrays",
    "title": "NumPy",
    "section": "Index, Slice and Reshape NumPy Arrays",
    "text": "Index, Slice and Reshape NumPy Arrays\n\nFrom List to Arrays\nOne-Dimensional List to Array\n\ndata = [11,12,33,47]\nprint(data)\n\n[11, 12, 33, 47]\n\n\n\ntype(data)\n\nlist\n\n\n\ndata_array = array(data)\nprint(data_array)\n\n[11 12 33 47]\n\n\n\ntype(data_array)\n\nnumpy.ndarray\n\n\n\ndata_array.shape\n\n(4,)\n\n\nTwo-Dimensional List of Lists to Array\n\ndata = [[11,22],\n       [33, 44],\n       [55, 66]]\n\n\nprint(data)\n\n[[11, 22], [33, 44], [55, 66]]\n\n\n\ndata_array = array(data)\n\n\nprint(data_array)\n\n[[11 22]\n [33 44]\n [55 66]]\n\n\n\ntype(data_array)\n\nnumpy.ndarray\n\n\n\ndata_array.shape\n\n(3, 2)\n\n\n\n\nArray Indexing\nOne-Dimensional Indexing\n\ndata = array([11,22,33,44,55])\n\n\ndata[0]\n\n11\n\n\n\ndata[4]\n\n55\n\n\n\n#data[5]\n\n\ndata[-1]\n\n55\n\n\n\ndata[-5]\n\n11\n\n\nTwo-Dimensional Indexing\n\ndata = array([[11,22],\n            [33, 44],\n            [55, 66]])\n\n\ndata[0,0]\n\n11\n\n\n\ndata[0, ]\n\narray([11, 22])\n\n\n\n\nArray Slicing\ndata [from : to]\nOne-Dimensional Slicing\n\ndata = array([11,22,33,44,55])\n\n\nprint(data[:])\n\n[11 22 33 44 55]\n\n\n\nprint(data[0:3])\n\n[11 22 33]\n\n\n\nprint(data[-2:])\n\n[44 55]\n\n\n\nTwo-Dimensional Slicing\nSplit Input and Output Features\nX = [: , : -1] this is the input\ny = [: , -1] this is the output\n\ndata = array([[11,22,33],\n             [44,55,66],\n             [77,88,99]])\n\n\nX, y = data[: , :-1], data[:, -1]\n\n\nprint(X)\n\n[[11 22]\n [44 55]\n [77 88]]\n\n\n\nprint(y)\n\n[33 66 99]\n\n\nSplit Train and Test Rows\ntrain = data [ : split , :]\ntest = data [split : , :]\n\ndata = array([[11,22,33],\n             [44,55,66],\n             [77,88,99]])\n\n\nsplit = 2\n\n\ntrain, test = data[:split, :], data[split:,:]\n\n\ntrain\n\narray([[11, 22, 33],\n       [44, 55, 66]])\n\n\n\ntest\n\narray([[77, 88, 99]])\n\n\n\n\n\nArray Reshaping\nData shape\n\ndata = array([11,22,33,44])\ndata.shape\n\n(4,)\n\n\n\ndata = array([[11,22],\n             [33,44],\n             [55,66]])\ndata.shape\n\n(3, 2)\n\n\n\ndata.shape[0]\n\n3\n\n\n\ndata.shape[1]\n\n2\n\n\nReshape 1D to 2D Array\ndata = data.reshape( (data.shape[0] , 1) )\n\ndata = array([11,22,33,44,55])\ndata.shape\n\n(5,)\n\n\n\ndata = data.reshape((data.shape[0], 1))\ndata.shape\n\n(5, 1)\n\n\nReshape 2D to 3D Array\ndata = data.reshape( (data.shape[0], data.shape[1], 1) )\n\ndata = array([[11,22],\n             [33,44],\n             [55,66]])\ndata.shape\n\n(3, 2)\n\n\n\ndata = data.reshape((data.shape[0], data.shape[1], 1))\ndata.shape\n\n(3, 2, 1)"
  },
  {
    "objectID": "01-linear-algebra/01-numpy.html#numpy-array-broadcasting",
    "href": "01-linear-algebra/01-numpy.html#numpy-array-broadcasting",
    "title": "NumPy",
    "section": "NumPy Array Broadcasting",
    "text": "NumPy Array Broadcasting\n\nBroadcasting in NumPy\nScalar and One-Dimensional Array\na = [a1, a2, a3]\nb\nc = a + b\nc = [a1+b, a2+b, a3+b]\n\na = array([1,2,3])\nprint(a)\n\n[1 2 3]\n\n\n\nb = 2\nprint(b)\n\n2\n\n\n\nc = a + b\nprint(c)\n\n[3 4 5]\n\n\nScalar and Two-Dimensional Array\n\na = array([[1,2,3],\n         [1,2,3]])\nprint(a)\n\n[[1 2 3]\n [1 2 3]]\n\n\n\nb = 2\n\n\nc = a + b\n\n\nprint(c)\n\n[[3 4 5]\n [3 4 5]]\n\n\nOne-Dimensional and Two-Dimensional Arrays\n\na = array([[1,2,3],\n          [1,2,3]])\nprint(a)\n\n[[1 2 3]\n [1 2 3]]\n\n\n\nb = array([4,5,6])\n\n\nc = a + b\n\n\nprint(c)\n\n[[5 7 9]\n [5 7 9]]\n\n\n\n\nLimitations of Broadcasting\nA.shape = (2 x 3)\nb.shape = (3)\nA.shape = (2 x 3)\nb.shape = (1 x 3)\nA.shape = (2 x 3)\nb.shape = (1)\nA.shape = (2 x 3)\nb.shape = (1 x 1)\nA.shape = (2 x 3)\nb.shape = (1 x 2)\n\na = array([[1,2,3],\n          [1,2,3]])\nprint(a)\n\n[[1 2 3]\n [1 2 3]]\n\n\n\nb = array([1,2])\nprint(b)\n\n[1 2]\n\n\n\n#c = a + b"
  },
  {
    "objectID": "07-references/references.html",
    "href": "07-references/references.html",
    "title": "Math References",
    "section": "",
    "text": "Khan academy"
  },
  {
    "objectID": "05-definition/definition.html",
    "href": "05-definition/definition.html",
    "title": "Short Definition",
    "section": "",
    "text": "Random experiment\nSapmle space\nEvent\nRandom variables * Discrete Random Variables * Continuous Random Variables\nJoint, Marginal, and Conditional Probability\nProbbaility Distribution * PMF * PDF * CDF * PPF: Percent-Point Function\nProbbaility Distributions * Discrete Probability Distributions * Bernoulli Distribution * Binomial Distribution * Multinoulli Distribution * Multinomial Distribution * Geometric distribution\n\nContinuous Probability Distributions\n\nNormal Distribution\nExponential Distribution\nPareto Distribution\n\nExpected Value. The average value of a random variable.\nVariance. The average spread of values around the expected value.\nCovariance: The variance between two variables is called the covariance and summarizes the linear relationship for how two random variables change together."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Math for ML and DL",
    "section": "",
    "text": "I will write my notes for math for machine learning."
  },
  {
    "objectID": "03-statistics/statistics.html#hypothesis-testing",
    "href": "03-statistics/statistics.html#hypothesis-testing",
    "title": "Statistics Methods for Machine Learning",
    "section": "Hypothesis Testing",
    "text": "Hypothesis Testing\n\nStatistical Hypothesis Testing\n\n\nStatistical Distributions\n\n\nCritical Values\n\n\nCovariance and Correlation\n\n\nSignificance Tests\n\n\nEffect Size\n\n\nStatistical Power"
  },
  {
    "objectID": "03-statistics/statistics.html#resampling-methods",
    "href": "03-statistics/statistics.html#resampling-methods",
    "title": "Statistics Methods for Machine Learning",
    "section": "Resampling Methods",
    "text": "Resampling Methods\n\nIntroduction to Resampling\n\n\nEstimation with Bootstrap\n\n\nEstimation with Cross-Validation"
  },
  {
    "objectID": "03-statistics/statistics.html#estimation-statistics",
    "href": "03-statistics/statistics.html#estimation-statistics",
    "title": "Statistics Methods for Machine Learning",
    "section": "Estimation Statistics",
    "text": "Estimation Statistics\n\nIntroduction to Estimation Statistics\n\n\nTolerance Intervals\n\n\nConfidence Intervals\n\n\nPrediction Intervals"
  },
  {
    "objectID": "03-statistics/statistics.html#nonparametric-methods",
    "href": "03-statistics/statistics.html#nonparametric-methods",
    "title": "Statistics Methods for Machine Learning",
    "section": "Nonparametric Methods",
    "text": "Nonparametric Methods\n\nRank Data\n\n\nNormality Tests\n\n\nMake Data Normal\n\n\n5-Number Summary\n\n\nRank Correlation\n\n\nRank Significance Tests\n\n\nIndependence Test"
  },
  {
    "objectID": "02-probability/04-maximum_likelihood.html",
    "href": "02-probability/04-maximum_likelihood.html",
    "title": "Maximum Likelihood",
    "section": "",
    "text": "Density estimation is the problem of estimating the probability distribution for a sample of observations from a problem domain. There are many techniques for solving density estimation, although a common framework used throughout the field of machine learning is maximum likelihood estimation. Maximum likelihood estimation involves defining a likelihood function for calculating the conditional probability of observing the data sample given a probability distribution and distribution parameters. This approach can be used to search a space of possible distributions and parameters. This flexible probabilistic framework also provides the foundation for many machine learning algorithms, including important methods such as linear regression and logistic regression for predicting numeric values and class labels respectively, but also more generally for deep learning artificial neural networks. In this tutorial, you will discover a gentle introduction to maximum likelihood estimation. After reading this tutorial, you will know: * Maximum Likelihood Estimation is a probabilistic framework for solving the problem of density estimation. * It involves maximizing a likelihood function in order to find the probability distribution and parameters that best explain the observed data. * It provides a framework for predictive modeling in machine learning where finding model parameters can be framed as an optimization problem."
  },
  {
    "objectID": "02-probability/04-maximum_likelihood.html#maximum-likelihood-estimation",
    "href": "02-probability/04-maximum_likelihood.html#maximum-likelihood-estimation",
    "title": "Maximum Likelihood",
    "section": "Maximum Likelihood Estimation",
    "text": "Maximum Likelihood Estimation\n\nProblem of Probability Density Estimation\nA common modeling problem involves how to estimate a joint probability distribution for a dataset. For example, given a sample of observation (X) from a domain (x 1 , x 2 , x 3 , · · · , x n ), where each observation is drawn independently from the domain with the same probability distribution (so-called independent and identically distributed, i.i.d., or close to it). Density estimation involves selecting a probability distribution function and the parameters of that distribution that best explain the joint probability distribution of the observed data (X).\n\nHow do you choose the probability distribution function?\nHow do you choose the parameters for the probability distribution function?\n\nThis problem is made more challenging if the sample (X) drawn from the population is small and has noise, meaning that any evaluation of an estimated probability density function and its parameters will have some error. There are many techniques for solving this problem, although two common approaches are: * Maximum a Posteriori (MAP), a Bayesian method. * Maximum Likelihood Estimation (MLE), frequentist method.\nThe main difference is that MLE assumes that all solutions are equally likely beforehand, whereas MAP allows prior information about the form of the solution to be harnessed. In this tutorial, we will take a closer look at the MLE method and its relationship to applied machine learning.\n\n\nMaximum Likelihood Estimation\nOne solution to probability density estimation is referred to as Maximum Likelihood Estimation, or MLE for short. Maximum Likelihood Estimation involves treating the problem as an optimization or search problem, where we seek a set of parameters that results in the best fit for the joint probability of the data sample (X). First, it involves defining a parameter called theta (θ) that defines both the choice of the probability density function and the parameters of that distribution. It may be a vector of numerical values whose values change smoothly and map to different probability distributions and their parameters. In Maximum Likelihood Estimation, we wish to maximize the probability of observing the data from the joint probability distribution given a specific probability distribution and its parameters, stated formally as:\nP (X|θ)\nThis conditional probability is often stated using the semicolon (;) notation instead of the bar notation (|) because θ is not a random variable, but instead an unknown parameter. For example:\nP (X; θ)\nOr:\nP (x 1 , x 2 , x 3 , · · · , x n ; θ)\nThis resulting conditional probability is referred to as the likelihood of observing the data given the model parameters and written using the notation L() to denote the likelihood function. For example:\nL(X; θ)\nThe objective of Maximum Likelihood Estimation is to find the set of parameters (θ) that maximize the likelihood function, e.g. result in the largest likelihood value.\nmax L(X; θ)\nWe can unpack the conditional probability calculated by the likelihood function. Given that the sample is comprised of n examples, we can frame this as the joint probability of the observed data samples x 1 , x 2 , x 3 , · · · , x n in X given the probability distribution parameters (θ).\nL(x 1 , x 2 , x 3 , · · · , x n ; θ)\nThe joint probability distribution can be restated as the multiplication of the conditional probability for observing each example given the distribution parameters.\nn Y P (x i ; θ)\nMultiplying many small probabilities together can be numerically unstable in practice, therefore, it is common to restate this problem as the sum of the log conditional probabilities of observing each example given the model parameters.\nWhere log with base-e called the natural logarithm is commonly used.\nThis product over many probabilities can be inconvenient […] it is prone to numerical underflow. To obtain a more convenient but equivalent optimization problem, we observe that taking the logarithm of the likelihood does not change its arg max but does conveniently transform a product into a sum\nGiven the frequent use of log in the likelihood function, it is commonly referred to as a log-likelihood function. It is common in optimization problems to prefer to minimize the cost function, rather than to maximize it. Therefore, the negative of the log-likelihood function is used, referred to generally as a Negative Log-Likelihood (NLL) function.\nIn software, we often phrase both as minimizing a cost function. Maximum likelihood thus becomes minimization of the negative log-likelihood (NLL) …\n\n\nRelationship to Machine Learning\nThis problem of density estimation is directly related to applied machine learning. We can frame the problem of fitting a machine learning model as the problem of probability density estimation. Specifically, the choice of model and model parameters is referred to as a modeling hypothesis h, and the problem involves finding h that best explains the data X.\nP (X; h)\nWe can, therefore, find the modeling hypothesis that maximizes the likelihood function.\nmax L(X; h)\nOr, more fully:\nThis provides the basis for estimating the probability density of a dataset, typically used in unsupervised machine learning algorithms; for example: * Clustering algorithms.\nUsing the expected log joint probability as a key quantity for learning in a proba- bility model with hidden variables is better known in the context of the celebrated expectation maximization or EM algorithm.\nThe Maximum Likelihood Estimation framework is also a useful tool for supervised machine learning. This applies to data where we have input and output variables, where the output variable may be a numerical value or a class label in the case of regression and classification predictive modeling retrospectively. We can state this as the conditional probability of the output y given the input (X) given the modeling hypothesis (h).\nmax L(y|X; h)\nOr, more fully:\nThe maximum likelihood estimator can readily be generalized to the case where our goal is to estimate a conditional probability P (y|x; θ) in order to predict y given x. This is actually the most common situation because it forms the basis for most supervised learning.\nThis means that the same Maximum Likelihood Estimation framework that is generally used for density estimation can be used to find a supervised learning model and parameters. This provides the basis for foundational linear modeling techniques, such as: * Linear Regression, for predicting a numerical value. * Logistic Regression, for binary classification.\nIn the case of linear regression, the model is constrained to a line and involves finding a set of coefficients for the line that best fits the observed data. Fortunately, this problem can be solved analytically (e.g. directly using linear algebra). In the case of logistic regression, the model defines a line and involves finding a set of coefficients for the line that best separates the classes. This cannot be solved analytically and is often solved by searching the space of possible coefficient values using an efficient optimization algorithm such as the BFGS algorithm or variants.\nBoth methods can also be solved less efficiently using a more general optimization algorithm such as stochastic gradient descent. In fact, most machine learning models can be framed under the maximum likelihood estimation framework, providing a useful and consistent way to approach predictive modeling as an optimization problem. An important benefit of the maximum likelihood estimator in machine learning is that as the size of the dataset increases, the quality of the estimator continues to improve.\nIn this tutorial, you discovered a gentle introduction to maximum likelihood estimation. Specifi- cally, you learned: * Maximum Likelihood Estimation is a probabilistic framework for solving the problem of density estimation. * It involves maximizing a likelihood function in order to find the probability distribution and parameters that best explain the observed data. * It provides a framework for predictive modeling in machine learning where finding model parameters can be framed as an optimization problem."
  },
  {
    "objectID": "02-probability/04-maximum_likelihood.html#linear-regression-with-maximum-likelihood-estimation",
    "href": "02-probability/04-maximum_likelihood.html#linear-regression-with-maximum-likelihood-estimation",
    "title": "Maximum Likelihood",
    "section": "Linear Regression With Maximum Likelihood Estimation",
    "text": "Linear Regression With Maximum Likelihood Estimation\nLinear regression is a classical model for predicting a numerical quantity. The parameters of a linear regression model can be estimated using a least squares procedure or by a maximum likelihood estimation procedure. Maximum likelihood estimation is a probabilistic framework for automatically finding the probability distribution and parameters that best describe the observed data. Supervised learning can be framed as a conditional probability problem, and maximum likelihood estimation can be used to fit the parameters of a model that best summarizes the conditional probability distribution, so-called conditional maximum likelihood estimation. A linear regression model can be fit under this framework and can be shown to derive an identical solution to a least squares approach. In this tutorial, you will discover linear regression with maximum likelihood estimation. After reading this tutorial, you will know: * Linear regression is a model for predicting a numerical quantity and maximum likelihood estimation is a probabilistic framework for estimating model parameters. * Coefficients of a linear regression model can be estimated using a negative log-likelihood function from maximum likelihood estimation. * The negative log-likelihood function can be used to derive the least squares solution to linear regression.\n\nLinear Regression as Maximum Likelihood\n\n\nLeast Squares and Maximum Likelihood"
  },
  {
    "objectID": "02-probability/04-maximum_likelihood.html#logistic-regression-with-maximum-likelihood-estimation",
    "href": "02-probability/04-maximum_likelihood.html#logistic-regression-with-maximum-likelihood-estimation",
    "title": "Maximum Likelihood",
    "section": "Logistic Regression With Maximum Likelihood Estimation",
    "text": "Logistic Regression With Maximum Likelihood Estimation\n\nLogistic Regression and Log-Odds\n\nfrom math import log\nfrom math import exp\n\n\nprob = 0.8\nprint(f'Probability is: {prob}')\n\n\nodds = prob / (1 - prob)\nprint(f'Odds is: {odds: .1f}')\n\n\nprob = odds/ (odds +1)\nprint(f'Probability is: {prob}')\n\n\nlogodds = log(odds)\nprint(f'Log-Odds is: {logodds: 0.2f}')\n\n\nprob = 1 / (1 + exp(-logodds))\nprint(f'Probability is: {prob}')\n\n\n\nLogistic Regression as Maximum Likelihood\n\ndef likelihood(y, yhat):\n    return yhat*y + (1 - yhat)*(1 - y)\n\n\ny, yhat = 1, 0.9\nprint(f'y={y}, yhat={yhat}, likelihood: {likelihood(y, yhat):.3f}')\n\n\ny, yhat = 1, 0.1\nprint(f'y={y}, yhat={yhat}, likelihood: {likelihood(y, yhat):.3f}')\n\n\ny, yhat = 0, 0.1\nprint(f'y={y}, yhat={yhat}, likelihood: {likelihood(y, yhat):.3f}')\n\n\ny, yhat = 0, 0.9\nprint(f'y={y}, yhat={yhat}, likelihood: {likelihood(y, yhat):.3f}')"
  },
  {
    "objectID": "02-probability/04-maximum_likelihood.html#expectation-maximization-em-algorithm",
    "href": "02-probability/04-maximum_likelihood.html#expectation-maximization-em-algorithm",
    "title": "Maximum Likelihood",
    "section": "Expectation Maximization (EM Algorithm)",
    "text": "Expectation Maximization (EM Algorithm)\n\nExpectation-Maximization Algorithm\n\n\nGaussian Mixture Model and the EM Algorithm\n\n\nExample of Gaussian Mixture Model\n\nfrom numpy import hstack\nfrom numpy.random import normal\nfrom sklearn.mixture import GaussianMixture\n\n\nX1 = normal(loc=20, scale=5, size=3000)\nX2 = normal(loc=40, scale=5, size=7000)\n\n\nX = hstack((X1, X2))\nX = X.reshape(len(X), 1)\n\n\nmodel = GaussianMixture(n_components=2, init_params='random')\nmodel.fit(X)\n\nGaussianMixture(init_params='random', n_components=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.GaussianMixtureGaussianMixture(init_params='random', n_components=2)\n\n\n\nyhat = model.predict(X)\n\n\nprint(yhat[:100])\n\n[0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0\n 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n\n\n\nprint(yhat[-100:])\n\n[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]"
  },
  {
    "objectID": "02-probability/04-maximum_likelihood.html#probabilistic-model-selection-with-aic-bic-and-mdl",
    "href": "02-probability/04-maximum_likelihood.html#probabilistic-model-selection-with-aic-bic-and-mdl",
    "title": "Maximum Likelihood",
    "section": "Probabilistic Model Selection with AIC, BIC, and MDL",
    "text": "Probabilistic Model Selection with AIC, BIC, and MDL"
  },
  {
    "objectID": "02-probability/03-distributions.html",
    "href": "02-probability/03-distributions.html",
    "title": "Probability Distributions",
    "section": "",
    "text": "The structure and type of the probability distribution varies based on the properties of the random variable, such as continuous or discrete, and this, in turn, impacts how the distribution might be summarized or how to calculate the most likely outcome and its probability.\nRandom Variable\nA random variable is often denoted as a capital letter, e.g. X, and values of the random variable are denoted as a lowercase letter and an index, e.g. x 1 , x 2 , x 3 . Upper-case letters like X denote a random variable, while lower-case letters like x denote the value that the random variable takes.\nThe values that a random variable can take is called its domain, and the domain of a random variable may be discrete or continuous.\nA discrete random variable has a finite set of states: for example, colors of a car. A random variable that has values true or false is discrete and is referred to as a Boolean random variable: for example, a coin toss. A continuous random variable has a range of numerical values: for example, the height of humans. * Discrete Random Variable. Values are drawn from a finite set of states. * Boolean Random Variable. Values are drawn from the set of {true, false}. * Continuous Random Variable. Values are drawn from a range of real-valued numerical values.\nA value of a random variable can be specified via an equals operator: for example, X = T rue. The probability of a random variable is denoted as a function using the upper case P or P r; for example, P (X) is the probability of all values for the random variable X. The probability of a value of a random variable can be denoted P (X = T rue), in this case indicating the probability of the X random variable having the value True."
  },
  {
    "objectID": "02-probability/03-distributions.html#probability-distribution",
    "href": "02-probability/03-distributions.html#probability-distribution",
    "title": "Probability Distributions",
    "section": "Probability Distribution",
    "text": "Probability Distribution\nA probability distribution is a summary of probabilities for the possible values of a random variable. As a distribution, the mapping of the values of a random variable to a probability has a shape when all values of the random variable are lined up. The distribution also has general properties that can be measured. Two important properties of a probability distribution are the expected value and the variance. Mathematically, these are referred to as the first and second moments of the distribution. Other moments include the skewness (3rd moment) and the kurtosis (4th moment).\nThe expected value is the average or mean value of a random variable X. This is the most likely value or the outcome with the highest probability. It is typically denoted as a function of the uppercase letter E with square brackets: for example, E[X] for the expected value of X or E[f (x)] where the function f () is used to sample a value from the domain of X.\nThe expectation value (or the mean) of a random variable X is denoted by E(X).\nThe variance is the spread of the values of a random variable from the mean. This is typically denoted as a function V ar; for example, V ar(X) is the variance of the random variable X or V ar(f (x)) for the variance of values drawn from the domain of X using the function f (). The square root of the variance normalizes the value and is referred to as the standard deviation. The variance between two variables is called the covariance and summarizes the linear relationship for how two random variables change together.\n\nExpected Value. The average value of a random variable.\nVariance. The average spread of values around the expected value.\nCovariance: The variance between two variables is called the covariance and summarizes the linear relationship for how two random variables change together.\n\nEach random variable has its own probability distribution, although the probability distribu- tion of many different random variables may have the same shape. Most common probability distributions can be defined using a few parameters and provide procedures for calculating the expected value and the variance. The structure of the probability distribution will differ depending on whether the random variable is discrete or continuous."
  },
  {
    "objectID": "02-probability/03-distributions.html#discrete-probability-distributions",
    "href": "02-probability/03-distributions.html#discrete-probability-distributions",
    "title": "Probability Distributions",
    "section": "Discrete Probability Distributions",
    "text": "Discrete Probability Distributions\nA discrete probability distribution summarizes the probabilities for a discrete random variable. The probability mass function, or PMF, defines the probability distribution for a discrete random variable. It is a function that assigns a probability for specific discrete values. A discrete probability distribution has a cumulative distribution function, or CDF. This is a function that assigns a probability that a discrete random variable will have a value of less than or equal to a specific discrete value.\n\nProbability Mass Function. Probability for a value for a discrete random variable.\nCumulative Distribution Function. Probability less than or equal to a value for a random variable.\n\nThe values of the random variable may or may not be ordinal, meaning they may or may not be ordered on a number line, e.g. counts can, car color cannot. In this case, the structure of the PMF and CDF may be discontinuous, or may not form a neat or clean transition in relative probabilities across values. The expected value for a discrete random variable can be calculated from a sample using the mode, e.g. finding the most common value. The sum of probabilities in the PMF equals to one. Some examples of well known discrete probability distributions include: * Bernoulli and binomial distributions. * Multinoulli and multinomial distributions. * Poisson distribution.\n\nThe probabilities of dice rolls form a discrete uniform distribution.\nThe probabilities of coin flips form a Bernoulli distribution.\nThe probabilities car colors form a multinomial distribution.\n\nDiscrete probability distributions are used in machine learning, most notably in the modeling of binary and multiclass classification problems, but also in evaluating the performance for binary classification models, such as the calculation of confidence intervals, and in the modeling of the distribution of words in text for natural language processing. Knowledge of discrete probability distributions is also required in the choice of activation functions in the output layer of deep learning neural networks for classification tasks and selecting an appropriate loss function.\n\nThe probability of outcomes for discrete random variables can be summarized using discrete probability distributions.\nA single binary outcome has a Bernoulli distribution, and a sequence of binary outcomes has a Binomial distribution.\nA single categorical outcome has a Multinoulli distribution, and a sequence of categorical outcomes has a Multinomial distribution.\n\nA discrete random variable is a random variable that can have one of a finite set of specific outcomes. The two types of discrete random variables most commonly used in machine learning are binary and categorical. * Binary Random Variable: x ∈ {0, 1}. A binary random variable is a discrete random variable where the finite set of outcomes is in {0, 1}. * Categorical Random Variable: x ∈ {1, 2, · · · , K}. A categorical random variable is a discrete random variable where the finite set of outcomes is in {1, 2, · · · , K}, where K is the total number of unique outcomes.\nThe relationship between the events for a discrete random variable and their probabilities is called the discrete probability distribution and is summarized by a probability mass function, or PMF for short. For outcomes that can be ordered, the probability of an event equal to or less than a given value is defined by the cumulative distribution function, or CDF for short. The inverse of the CDF is called the percentage-point function and will give the discrete outcome that is less than or equal to a probability.\n\nPMF: Probability Mass Function, returns the probability of a given outcome.\nCDF: Cumulative Distribution Function, returns the probability of a value less than or equal to a given outcome.\nPPF: Percent-Point Function, returns a discrete value that is less than or equal to the given probability.\n\nThere are many common discrete probability distributions. The most common are the Bernoulli and Multinoulli distributions for binary and categorical discrete random variables respectively, and the Binomial and Multinomial distributions that generalize each to multiple independent trials.\n\nBinary Random Variable: Bernoulli Distribution.\nSequence of a Binary Random Variable: Binomial Distribution.\nCategorical Random Variable: Multinoulli Distribution.\nSequence of a Categorical Random Variable: Multinomial Distribution.\n\nThere are additional discrete probability distributions that you may want to explore, including the Poisson Distribution and the Discrete Uniform Distribution.\n\nBernoulli Distribution\nThe Bernoulli distribution is a discrete probability distribution that covers a case where an event will have a binary outcome as either a 0 or 1. x ∈ {0, 1}\nA Bernoulli trial is an experiment or case where the outcome follows a Bernoulli distribution.Some common examples of Bernoulli trials include: * The single flip of a coin that may have a heads (0) or a tails (1) outcome. * A single birth of either a boy (0) or a girl (1).\nA common example of a Bernoulli trial in machine learning might be a binary classification of a single example as the first class (0) or the second class (1). The distribution can be summarized by a single variable p that defines the probability of an outcome 1. Given this parameter, the probability for each event can be calculated as follows:\nP (x = 1) = p\nP (x = 0) = 1 − p\n\n\nBinomial Distribution\nThe repetition of multiple independent Bernoulli trials is called a Bernoulli process. The outcomes of a Bernoulli process will follow a Binomial distribution. As such, the Bernoulli distribution would be a Binomial distribution with a single trial. Some common examples of Bernoulli processes include: * A sequence of independent coin flips. * A sequence of independent births.\nThe performance of a machine learning algorithm on a binary classification problem can be analyzed as a Bernoulli process, where the prediction by the model on an example from a test set is a Bernoulli trial (correct or incorrect). The Binomial distribution summarizes the number of successes k in a given number of Bernoulli trials n, with a given probability of success for each trial p.\nWe can demonstrate this with a Bernoulli process where the probability of success is 30% or P (x = 1) = 0.3 and the total number of trials is 100 (k = 100).\nThis can be achieved via the binomial() NumPy function. This function takes the total number of trials and probability of success as arguments and returns the number of successful outcomes across the trials for one simulation.\n\n# example of simulating a binomial process and counting success\nfrom numpy.random import binomial\n\n# define the parameters of the distribution\np = 0.3 #probability of success\nn = 100 # Total number of trials\n\n# run a single simulation\nsuccess = binomial(n, p)\nprint(f'Total Success is: {success}')\n\nTotal Success is: 28\n\n\nWe can calculate the moments of this distribution, specifically the expected value or mean and the variance using the binom.stats() SciPy function.\n\nfrom scipy.stats import binom\n\nmean, var,_,_ = binom.stats(n, p, moments='mvsk')\nprint(f'Mean={mean}, Variance={var}')\n\nMean=30.0, Variance=21.0\n\n\nWe can use the probability mass function to calculate the likelihood of different numbers of successful outcomes for a sequence of trials, such as 10, 20, 30, to 100. We would expect 30 successful outcomes to have the highest probability.\nRunning the example defines the binomial distribution and calculates the probability for each number of successful outcomes in [10, 100] in groups of 10. The probabilities are multiplied by 100 to give percentages, and we can see that 30 successful outcomes has the highest probability at about 8.6%.\n\ndist = binom(n, p)\n\nfor n in range(10, 110, 10):\n    print(f'Probability of {n} success is: {dist.pmf(n)*100 :0.3f}%')\n\nProbability of 10 success is: 0.000%\nProbability of 20 success is: 0.758%\nProbability of 30 success is: 8.678%\nProbability of 40 success is: 0.849%\nProbability of 50 success is: 0.001%\nProbability of 60 success is: 0.000%\nProbability of 70 success is: 0.000%\nProbability of 80 success is: 0.000%\nProbability of 90 success is: 0.000%\nProbability of 100 success is: 0.000%\n\n\nRunning the example prints each number of successes in [10, 100] in groups of 10 and the probability of achieving that many success or less over 100 trials. As expected, after 50 successes or less covers 99.999% of the successes expected to happen in this distribution.\n\nfor n in range(10, 110, 10):\n    print(f'Probbaility of less than {n} success is: {dist.cdf(n)*100:0.3f}%')\n\nProbbaility of less than 10 success is: 0.000%\nProbbaility of less than 20 success is: 1.646%\nProbbaility of less than 30 success is: 54.912%\nProbbaility of less than 40 success is: 98.750%\nProbbaility of less than 50 success is: 99.999%\nProbbaility of less than 60 success is: 100.000%\nProbbaility of less than 70 success is: 100.000%\nProbbaility of less than 80 success is: 100.000%\nProbbaility of less than 90 success is: 100.000%\nProbbaility of less than 100 success is: 100.000%\n\n\n\n\nMultinoulli Distribution\nThe Multinoulli distribution, also called the categorical distribution, covers the case where an event will have one of K possible outcomes.\nx ∈ {1, 2, 3, · · · , K}\nIt is a generalization of the Bernoulli distribution from a binary variable to a categorical variable, where the number of cases K for the Bernoulli distribution is set to 2, K = 2. A common example that follows a Multinoulli distribution is: * A single roll of a die that will have an outcome in {1, 2, 3, 4, 5, 6}, e.g. K = 6.\nA common example of a Multinoulli distribution in machine learning might be a multiclass classification of a single example into one of K classes, e.g. one of three different species of the iris flower. The distribution can be summarized with p variables from p 1 to p K , each defining the probability of a given categorical outcome from 1 to K, and where all probabilities sum to 1.0.\nP (x = 1) = p 1 P (x = 2) = p 1 P (x = 3) = p 3 ··· P (x = K) = p K\nIn the case of a single roll of a die, the probabilities for each value would be 16 , or about 0.166 or about 16.6%.\n\n\nMultinomial Distribution\nThe repetition of multiple independent Multinoulli trials will follow a multinomial distribution. The multinomial distribution is a generalization of the binomial distribution for a discrete variable with K outcomes. An example of a multinomial process includes a sequence of independent dice rolls. A common example of the multinomial distribution is the occurrence counts of words in a text document, from the field of natural language processing. A multinomial distribution is summarized by a discrete random variable with K outcomes, a probability for each outcome from p 1 to p K , and n successive trials.\nWe can demonstrate this with a small example with 3 categories (K = 3) with equal probability (p=33.33%) and 100 trials. Firstly, we can use the multinomial() NumPy function to simulate 100 independent trials and summarize the number of times that the event resulted in each of the given categories. The function takes both the number of trials and the probabilities for each category as a list. The complete example is listed below.\nWe would expect each category to have about 33 events.\n\n# # example of simulating a multinomial process\nfrom numpy.random import multinomial\n\n# define the parameters of the distribution\np = [1.0/3.0, 1.0/3.0, 1.0/3.0]\nk = 100\n\n# run a single simulation\ndist = multinomial(k, p)\nfor i in range(len(dist)):\n    print(f'Case {i+1}: {dist[i]}')\n\nCase 1: 37\nCase 2: 36\nCase 3: 27\n\n\nWe might expect the idealized case of 100 trials to result in 33, 33, and 34 cases for events 1, 2 and 3 respectively. We can calculate the probability of this specific combination occurring in practice using the probability mass function or multinomial.pmf() SciPy function. The complete example is listed below.\nRunning the example reports the probability of less than 1% for the idealized number of cases of [33, 33, 34] for each event type.\n\n# calculate the probability for a given number of events of each type\n\nfrom scipy.stats import multinomial\n\n# define the parameters of the distribution\np = [1.0/3.0, 1.0/3.0, 1.0/3.0]\nk = 100\n\n# define the distribution\ndist = multinomial(k, p)\n\n# define a specific number of outcomes from 100 trials\ncases = [33, 33, 34]\n\n# calculate the probability for the case\npr = dist.pmf(cases)\n\n# print as a percentage\nprint( ' Case=%s, Probability: %.3f%% ' % (cases, pr*100))\n\n Case=[33, 33, 34], Probability: 0.813% \n\n\n\nThe probability of outcomes for discrete random variables can be summarized using discrete probability distributions.\nA single binary outcome has a Bernoulli distribution, and a sequence of binary outcomes has a Binomial distribution.\nA single categorical outcome has a Multinoulli distribution, and a sequence of categorical outcomes has a Multinomial distribution."
  },
  {
    "objectID": "02-probability/03-distributions.html#continuous-probability-distributions",
    "href": "02-probability/03-distributions.html#continuous-probability-distributions",
    "title": "Probability Distributions",
    "section": "Continuous Probability Distributions",
    "text": "Continuous Probability Distributions\nContinuous probability distributions are encountered in machine learning, most notably in the distribution of numerical input and output variables for models and in the distribution of errors made by models. Knowledge of the normal continuous probability distribution is also required more generally in the density and parameter estimation performed by many machine learning models.\nUnlike a discrete random variable, the probability for a given continuous random variable cannot be specified directly; instead, it is calculated as an integral (area under the curve) for a tiny interval around the specific outcome. The probability of an event equal to or less than a given value is defined by the cumulative distribution function, or CDF for short. The inverse of the CDF is called the percentage-point function and will give the discrete outcome that is less than or equal to a probability.\n\nPDF: Probability Density Function, returns the probability of a given continuous outcome.\nCDF: Cumulative Distribution Function, returns the probability of a value less than or equal to a given outcome.\nPPF: Percent-Point Function, returns a discrete value that is less than or equal to the given probability.\n\nA continuous probability distribution summarizes the probability for a continuous random variable. The probability distribution function, or PDF, defines the probability distribution for a continuous random variable. Like a discrete probability distribution, the continuous probability distribution also has a cumulative distribution function, or CDF, that defines the probability of a value less than or equal to a specific numerical value from the domain. * Probability Distribution Function. Probability for a value for a continuous random variable. * Cumulative Distribution Function. Probability less than or equal to a value for a random variable.\nThere are many common continuous probability distributions. The most common is the normal probability distribution. Practically all continuous probability distributions of interest belong to the so-called exponential family of distributions, which are just a collection of parameterized probability distributions (e.g. distributions that change based on the values of parameters).\nContinuous probability distributions play an important role in machine learning from the distribution of input variables to the models, the distribution of errors made by models, and in the models themselves when estimating the mapping between inputs and outputs.\nAs a continuous function, the structure forms a smooth curve. Some examples of well-known continuous probability distributions include: * Normal or Gaussian distribution. * Exponential distribution. * Pareto distribution.\nSome examples of domains with well-known continuous probability distributions include: * The probabilities of the heights of humans form a Normal distribution. * The probabilities of movies being a hit form a Power-law distribution. * The probabilities of income levels form a Pareto distribution.\n\nRandom variables in probability have a defined domain and can be continuous or discrete.\nProbability distributions summarize the relationship between possible values and their probability for a random variable.\nProbability density or mass functions map values to probabilities and cumulative distribution functions map outcomes less than or equal to a value to a probability.\n\n\nNormal Distribution\nThe normal distribution is also called the Gaussian distribution (named for Carl Friedrich Gauss) or the bell curve distribution. The distribution covers the probability of real-valued events from many different problem domains, making it a common and well-known distribution, hence the name normal. A continuous random variable that has a normal distribution is said to be normal or normally distributed. Some examples of domains that have normally distributed events include: * The heights of people. * The weights of babies. * The scores on a test.\nThe distribution can be defined using two parameters: * Mean (mu or μ): The expected value. * Variance (sigma 2 or σ 2 ): The spread from the mean. * Standard Deviation (sigma or σ): The average spread from the mean.\nA normal distribution with a mean of zero and a standard deviation of 1 is called a standard normal distribution, and often data is reduced or standardized to this for analysis for ease of interpretation and comparison.\nWe can define a distribution with a mean of 50 and a standard deviation of 5 and sample random numbers from this distribution. We can achieve this using the normal() NumPy function. Running the example prints 10 numbers randomly sampled from the defined normal distri- bution.\n\n# sample a normal distribution\nfrom numpy.random import normal\n\n# define the distribution\nmu = 50\nsigma = 5\nn = 10 \n\n# generate the sample\nsamples = normal(mu, sigma, n)\nprint(samples)\n\n[46.2058084  49.05613613 42.51165349 52.78140355 38.97850568 50.11030593\n 48.55113593 47.1842823  33.85826765 55.7023781 ]\n\n\nA sample of data can be checked to see if it is normal by plotting it and checking for the familiar normal shape, or by using statistical tests. If the samples of observations of a random variable are normally distributed, then they can be summarized by just the mean and variance, calculated directly on the samples. We can calculate the probability of each observation using the probability density function. A plot of these values would give us the tell-tale bell shape.\nWe can define a normal distribution using the norm() SciPy function and then calculate properties such as the moments, PDF, CDF, and more. The example below calculates the probability for integer values between 30 and 70 in our distribution and plots the result, then does the same for the cumulative probability.\n\n# pdf and cdf for a normal distribution\nfrom scipy.stats import norm\nfrom matplotlib import pyplot\n\n# define distribution parameters\nmu = 50\nsigma = 5\n\n# create distribution\ndist = norm(mu, sigma)\n\n# plot pdf\nvalues = [value for value in range(30, 70)]\nprobabilities = [dist.pdf(value) for value in values]\npyplot.plot(values, probabilities)\npyplot.show()\n\n\n\n\nRunning the example first calculates the probability for integers in the range [30, 70] and creates a line plot of values and probabilities. The plot shows the Gaussian or bell-shape with the peak of highest probability around the expected value or mean of 50 with a probability of about 8%.\nThe cumulative probabilities are then calculated for observations over the same range, showing that at the mean, we have covered about 50% of the expected values and very close to 100% after the value of about 65 or 3 standard deviations from the mean (50 + (3 × 5)).\n\n# plot cdf\ncprobs = [dist.cdf(value) for value in values]\npyplot.plot(values, cprobs)\npyplot.show()\n\n\n\n\nIn fact, the normal distribution has a heuristic or rule of thumb that defines the percentage of data covered by a given range by the number of standard deviations from the mean. It is called the 68-95-99.7 rule, which is the approximate percentage of the data covered by ranges defined by 1, 2, and 3 standard deviations from the mean.\nFor example, in our distribution with a mean of 50 and standard deviation of 5, we would expect 95% of the data to be covered by values that are 2 standard deviations from the mean, or 50 − (2 × 5) and 50 + (2 × 5) or between 40 and 60. We can confirm this by calculating the exact values using the percentage-point function. The middle 95% would be defined by the percentage point function value for 2.5% at the low end and 97.5% at the high end, where 97.5 to 2.5 gives the middle 95%. The complete example is listed below.\n\n# calculate the values that define the middle 95%\nfrom scipy.stats import norm\n\n# define distribution parameters\nmu = 50\nsigma = 5\n\n# create distribution\ndist = norm(mu, sigma)\n\nlow_end = dist.ppf(0.025)\nhigh_end = dist.ppf(0.975)\nprint(f'Middle 95% between {low_end: 0.1f} and {high_end: 0.1f}')\n\nMiddle 95% between  40.2 and  59.8\n\n\nAn important related distribution is the Log-Normal probability distribution.\n\n\nExponential Distribution\nThe exponential distribution is a continuous probability distribution where a few outcomes are the most likely with a rapid decrease in probability to all other outcomes. It is the continuous random variable equivalent to the geometric probability distribution for discrete random variables. Some examples of domains that have exponential distribution events include: * The time between clicks on a Geiger counter. * The time until the failure of a part. * The time until the default of a loan.\nThe distribution can be defined using one parameter: * Scale (Beta or β): The mean and standard deviation of the distribution.\nSometimes the distribution is defined more formally with a parameter lambda or rate. The beta parameter is defined as the reciprocal of the lambda parameter (β = λ 1 ) * Rate (lambda or λ) = Rate of change in the distribution.\nWe can define a distribution with a mean of 50 and sample random numbers from this distribution. We can achieve this using the exponential() NumPy function. The example below samples and prints 10 numbers from this distribution.\n\n# sample an exponential distribution\nfrom numpy.random import exponential\n\n# define the distribution\nbeta = 50\nn = 10\n\n# generate the sample\nsamples = exponential(beta, n)\nprint(samples)\n\n[ 26.00390615 238.69329655   0.24801164  39.32988685   6.80239972\n   2.16661426  20.20464917  13.32706905  22.96502669  65.09258785]\n\n\nRunning the example prints 10 numbers randomly sampled from the defined distribution.\nWe can define an exponential distribution using the expon() SciPy function and then calculate properties such as the moments, PDF, CDF, and more. The example below defines a range of observations between 50 and 70 and calculates the probability and cumulative probability for each and plots the result.\n\n# pdf and cdf for an exponential distribution\nfrom scipy.stats import expon\nfrom matplotlib import pyplot\n\n# define distribution parameter\nbeta = 50\n\n# create distribution\ndist = expon(beta)\n\n# plot pdf\nvalues = [value for value in range(50, 70)]\nprobabilities = [dist.pdf(value) for value in values]\npyplot.plot(values, probabilities)\npyplot.show()\n\n\n\n\n\n# plot cdf\ncprobs = [dist.cdf(value) for value in values]\npyplot.plot(values, cprobs)\npyplot.show()\n\n\n\n\nNext, the cumulative probabilities for each outcome are calculated and graphed as a line plot, showing that after perhaps a value of 55 that almost 100% of the expected values will be observed.\nAn important related distribution is the double exponential distribution, also called the Laplace distribution.\n\n\nPareto Distribution\nA Pareto distribution is named after Vilfredo Pareto and is may be referred to as a power-law distribution. It is also related to the Pareto principle (or 80/20 rule) which is a heuristic for continuous random variables that follow a Pareto distribution, where 80% of the events are covered by 20% of the range of outcomes, e.g. most events are drawn from just 20% of the range of the continuous variable. The Pareto principle is just a heuristic for a specific Pareto distribution, specifically the Pareto Type II distribution, that is perhaps most interesting and on which we will focus. Some examples of domains that have Pareto distributed events include: * The income of households in a country. * The total sales of books. * The scores by players on a sports team.\nThe distribution can be defined using one parameter: * Shape (alpha or α): The steepness of the decease in probability.\nValues for the shape parameter are often small, such as between 1 and 3, with the Pareto principle given when alpha is set to 1.161. We can define a distribution with a shape of 1.1 and sample random numbers from this distribution. We can achieve this using the pareto() NumPy function.\n\n# sample a pareto distribution\nfrom numpy.random import pareto\n\n# define the distribution\nalpha = 1.1\nn = 10\n\n# generate the sample\nsamples = pareto(alpha, n)\nprint(samples)\n\n[ 0.4774442   0.28700929 10.97301841 34.92526594  1.42528873  2.85659883\n  0.1570074   0.31605884  0.07072592  8.23924924]\n\n\nWe can define a Pareto distribution using the pareto() SciPy function and then calculate properties, such as the moments, PDF, CDF, and more. The example below defines a range of observations between 1 and about 10 and calculates the probability and cumulative probability for each and plots the result.\n\n# pdf and cdf for a pareto distribution\nfrom scipy.stats import pareto\nfrom matplotlib import pyplot\n\n# define distribution parameter\nalpha = 1.5\n\n# create distribution\ndist = pareto(alpha)\n\n# plot pdf\nvalues  = [value/10.0 for value in range(10, 100)]\nprobabilities = [dist.pdf(value) for value in values]\npyplot.plot(values, probabilities)\npyplot.show()\n\n\n\n\nNext, the cumulative probabilities for each outcome are calculated and graphed as a line plot, showing a rise that is less steep than the exponential distribution seen in the previous section.\n\n# plot cdf\ncprobs = [dist.cdf(value) for value in values]\npyplot.plot(values, cprobs)\npyplot.show()"
  },
  {
    "objectID": "02-probability/03-distributions.html#probability-density-estimation",
    "href": "02-probability/03-distributions.html#probability-density-estimation",
    "title": "Probability Distributions",
    "section": "Probability Density Estimation",
    "text": "Probability Density Estimation\nProbability density is the relationship between observations and their probability. Some outcomes of a random variable will have low probability density and other outcomes will have a high probability density. The overall shape of the probability density is referred to as a probability distribution, and the calculation of probabilities for specific outcomes of a random variable is performed by a probability density function, or PDF for short. It is useful to know the probability density function for a sample of data in order to know whether a given observation is unlikely, or so unlikely as to be considered an outlier or anomaly and whether it should be removed. It is also helpful in order to choose appropriate learning methods that require input data to have a specific probability distribution. It is unlikely that the probability density function for a random sample of data is known. As such, the probability density must be approximated using a process known as probability density estimation.\n\nHistogram plots provide a fast and reliable way to visualize the probability density of a data sample.\nParametric probability density estimation involves selecting a common distribution and estimating the parameters for the density function from a data sample.\nNonparametric probability density estimation involves using a technique to fit a model to the arbitrary distribution of the data, like kernel density estimation.\n\nThis tutorial is divided into four parts; they are: 1. Probability Density 2. Summarize Density With a Histogram 3. Parametric Density Estimation 4. Nonparametric Density Estimation\nProbability Density\nA random variable x has a probability distribution p(x). The relationship between the outcomes of a random variable and its probability is referred to as the probability density, or simply the density. If a random variable is continuous, then the probability can be calculated via probability density function, or PDF for short. The shape of the probability density function across the domain for a random variable is referred to as the probability distribution and common probability distributions have names, such as uniform, normal, exponential, and so on.\nGiven a random variable, we are interested in the density of its probabilities. For example, given a random sample of a variable, we might want to know things like the shape of the probability distribution, the most likely value, the spread of values, and other properties. Knowing the probability distribution for a random variable can help to calculate moments of the distribution, like the mean and variance, but can also be useful for other more general considerations, like determining whether an observation is unlikely or very unlikely and might be an outlier or anomaly.The problem is, we may not know the probability distribution for a random variable. We rarely do know the distribution because we don’t have access to all possible outcomes for a random variable. In fact, all we have access to is a sample of observations. As such, we must select a probability distribution.\nThis problem is referred to as probability density estimation, or simply density estimation, as we are using the observations in a random sample to estimate the general density of probabilities beyond just the sample of data we have available.\nThere are a few steps in the process of density estimation for a random variable. The first step is to review the density of observations in the random sample with a simple histogram. From the histogram, we might be able to identify a common and well-understood probability distribution that can be used, such as a normal distribution. If not, we may have to fit a model to estimate the distribution.\nIn the following sections, we will take a closer look at each one of these steps in turn. We will focus on univariate data, e.g. one random variable, in this tutorial for simplicity. Although the steps are applicable for multivariate data, they can become more challenging if the number of variables increases.\n\nSummarize Density With a Histogram\nThe first step in density estimation is to create a histogram of the observations in the random sample. A histogram is a plot that involves first grouping the observations into bins and counting the number of events that fall into each bin. The counts, or frequencies of observations, in each bin are then plotted as a bar graph with the bins on the x-axis and the frequency on the y-axis. The choice of the number of bins is important as it controls the coarseness of the distribution (number of bars) and, in turn, how well the density of the observations is plotted. It is a good idea to experiment with different bin sizes for a given data sample to get multiple perspectives or views on the same data.\nWe can create a random sample drawn from a normal distribution and pretend we don’t know the distribution, then create a histogram of the data. The normal() NumPy function will achieve this and we will generate 1,000 samples with a mean of 0 and a standard deviation of 1, e.g. a standard Gaussian. The complete example is listed below.\n\n# example of plotting a histogram of a random sample\nfrom numpy.random import normal\nfrom matplotlib import pyplot\n\n# generate a sample\nsamples = normal(size=1000)\n\n# plot a histogram of the sample\npyplot.hist(samples, bins=10)\npyplot.show()\n\n\n\n\nRunning the example draws a sample of random observations and creates the histogram with 10 bins. We can clearly see the shape of the normal distribution.\nReviewing a histogram of a data sample with a range of different numbers of bins will help to identify whether the density looks like a common probability distribution or not. In most cases, you will see a unimodal distribution, such as the familiar bell shape of the normal, the flat shape of the uniform, or the descending or ascending shape of an exponential or Pareto distribution. You might also see complex distributions, such as two peaks that don’t disappear with different numbers of bins, referred to as a bimodal distribution, or multiple peaks, referred to as a multimodal distribution. You might also see a large spike in density for a given value or small range of values indicating outliers, often occurring on the tail of a distribution far away from the rest of the density.\n\n\nParametric Density Estimation\nThe shape of a histogram of most random samples will match a well-known probability distribu- tion. The common distributions are common because they occur again and again in different and sometimes unexpected domains. Get familiar with the common probability distributions as it will help you to identify a given distribution from a histogram. Once identified, you can attempt to estimate the density of the random variable with a chosen probability distribution. This can be achieved by estimating the parameters of the distribution from a random sample of data.\nFor example, the normal distribution has two parameters: the mean and the standard deviation. Given these two parameters, we now know the probability distribution function. These parameters can be estimated from data by calculating the sample mean and sample standard deviation. We refer to this process as parametric density estimation. The reason is that we are using predefined functions to summarize the relationship between observations and their probability that can be controlled or configured with parameters, hence parametric. Once we have estimated the density, we can check if it is a good fit. This can be done in many ways, such as: * Plotting the density function and comparing the shape to the histogram. * Sampling the density function and comparing the generated sample to the real sample. * Using a statistical test to confirm the data fits the distribution.\nWe can demonstrate this with an example. We can generate a random sample of 100 observations from a normal distribution with a mean of 50 and a standard deviation of 5.\n\nfrom numpy.random import normal\n\n# generate a sample\nsamples = normal(loc=50, scale=5, size=1000)\n\nWe can then pretend that we don’t know the probability distribution and maybe look at a histogram and guess that it is normal. Assuming that it is normal, we can then calculate the parameters of the distribution, specifically the mean and standard deviation. We would not expect the mean and standard deviation to be 50 and 5 exactly given the small sample size and noise in the sampling process.\n\nfrom numpy import mean, std\n\n# calculate parameters\nsample_mean = mean(samples)\nsample_std = std(samples)\nprint(f'Mean= {sample_mean:0.3f}, Standard Deviation= {sample_std:.3f}')\n\nMean= 49.958, Standard Deviation= 4.987\n\n\nThen fit the distribution with these parameters, so-called parametric density estimation of our data sample. In this case, we can use the norm() SciPy function.\n\nfrom scipy.stats import norm\n\n# define the distribution\ndist = norm(sample_mean, sample_std)\n\nWe can then sample the probabilities from this distribution for a range of values in our domain, in this case between 30 and 70\n\n# sample probabilities for a range of outcomes\nvalues = [value for value in range(30, 70)]\nprobabilities = [dist.pdf(value) for value in values]\n\nFinally, we can plot a histogram of the data sample and overlay a line plot of the probabilities calculated for the range of values from the PDF. Importantly, we can convert the counts or frequencies in each bin of the histogram to a normalized probability to ensure the y-axis of the histogram matches the y-axis of the line plot. This can be achieved by setting the density argument to True in the call to hist().\n\n# plot the histogram and pdf\nfrom matplotlib import pyplot\npyplot.hist(samples, bins=10, density=True)\npyplot.plot(values, probabilities)\npyplot.show()\n\n\n\n\nIt is possible that the data does match a common probability distribution, but requires a transformation before parametric density estimation. For example, you may have outlier values that are far from the mean or center of mass of the distribution. This may have the effect of giving incorrect estimates of the distribution parameters and, in turn, causing a poor fit to the data. These outliers should be removed prior to estimating the distribution parameters. Another example is the data may have a skew or be shifted left or right. In this case, you might need to transform the data prior to estimating the parameters, such as taking the log or square root, or more generally, using a power transform like the Box-Cox transform. These types of modifications to the data may not be obvious and effective parametric density estimation may require an iterative process of:\nLoop Until Fit of Distribution to Data is Good Enough: 1. Estimating distribution parameters 2. Reviewing the resulting PDF against the data 3. Transforming the data to better fit the distribution\n\n\nNonparametric Density Estimation\nIn some cases, a data sample may not resemble a common probability distribution or cannot be easily made to fit the distribution. This is often the case when the data has two peaks (bimodal distribution) or many peaks (multimodal distribution). In this case, parametric density estimation is not feasible and alternative methods can be used that do not use a common distribution. Instead, an algorithm is used to approximate the probability distribution of the data without a pre-defined distribution, referred to as a nonparametric method.\nThe distributions will still have parameters but are not directly controllable in the same way as simple probability distributions. For example, a nonparametric method might estimate the density using all observations in a random sample, in effect making all observations in the sample parameters. Perhaps the most common nonparametric approach for estimating the probability density function of a continuous random variable is called kernel smoothing, or kernel density estimation, KDE for short.\n Kernel Density Estimation: Nonparametric method for using a dataset to estimating probabilities for new points.\nIn this case, a kernel is a mathematical function that returns a probability for a given value of a random variable. The kernel effectively smooths or interpolates the probabilities across the range of outcomes for a random variable such that the sum of probabilities equals one, a requirement of well-behaved probabilities. The kernel function weights the contribution of observations from a data sample based on their relationship or distance to a given query sample for which the probability is requested. A parameter, called the smoothing parameter or the bandwidth, controls the scope, or window of observations, from the data sample that contributes to estimating the probability for a given sample. As such, kernel density estimation is sometimes referred to as a Parzen-Rosenblatt window, or simply a Parzen window, after the developers of the method.\n Smoothing Parameter (bandwidth): Parameter that controls the number of samples or window of samples used to estimate the probability for a new point.\nA large window may result in a coarse density with little details, whereas a small window may have too much detail and not be smooth or general enough to correctly cover new or unseen examples. The contribution of samples within the window can be shaped using different functions, sometimes referred to as basis functions, e.g. uniform normal, etc., with different effects on the smoothness of the resulting density function.\nBasis Function (kernel ): The function chosen used to control the contribution of samples in the dataset toward estimating the probability of a new point.\nAs such, it may be useful to experiment with different window sizes and different contribution functions and evaluate the results against histograms of the data. We can demonstrate this with an example. First, we can construct a bimodal distribution by combining samples from two different normal distributions. Specifically, 300 examples with a mean of 20 and a standard deviation of 5 (the smaller peak), and 700 examples with a mean of 40 and a standard deviation of 5 (the larger peak). The means were chosen close together to ensure the distributions overlap in the combined sample. The complete example of creating this sample with a bimodal probability distribution and plotting the histogram is listed below.\n\n# example of a bimodal data sample\nfrom matplotlib import pyplot\nfrom numpy.random import normal\nfrom numpy import hstack\n\n\n# generate a sample\nsample1 = normal(loc=20, scale=5, size=300)\nsample2 = normal(loc=40, scale=5, size=700)\nsample = hstack((sample1, sample2))\nsample.shape\n\n(1000,)\n\n\n\n# plot the histogram\npyplot.hist(sample, bins=50)\npyplot.show()\n\n\n\n\nData with this distribution does not nicely fit into a common probability distribution, by design. It is a good case for using a nonparametric kernel density estimation method.\nThe scikit-learn machine learning library provides the KernelDensity class that implements kernel density estimation. First, the class is constructed with the desired bandwidth (window size) and kernel (basis function) arguments. It is a good idea to test different configurations on your data. In this case, we will try a bandwidth of 2 and a Gaussian kernel. The class is then fit on a data sample via the fit() function. The function expects the data to have a 2D shape with the form [rows, columns], therefore we can reshape our data sample to have 1,000 rows and 1 column.\n\n# fit density\nfrom sklearn.neighbors import KernelDensity\nmodel = KernelDensity(bandwidth=2, kernel='gaussian')\nsamples = samples.reshape(len(samples), 1)\nsamples.shape\n\n(1000, 1)\n\n\n\nmodel.fit(samples)\n\nKernelDensity(bandwidth=2)In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.KernelDensityKernelDensity(bandwidth=2)\n\n\nWe can then evaluate how well the density estimate matches our data by calculating the probabilities for a range of observations and comparing the shape to the histogram, just like we did for the parametric case in the prior section. The score samples() function on the KernelDensity will calculate the log probability for an array of samples. We can create a range of samples from 1 to 60, about the range of our domain, calculate the log probabilities, then invert the log operation by calculating the exponent or exp() to return the values to the range 0-1 for normal probabilities.\n\n# sample probabilities for a range of outcomes\nfrom numpy import asarray, exp\nvalues = asarray([value for value in range(1, 60)])\nvalues = values.reshape((len(values), 1))\nprobabilities = model.score_samples(values)\nprobabilities = exp(probabilities)\n\nFinally, we can create a histogram with normalized frequencies and an overlay line plot of values to estimated probabilities.\n\npyplot.hist(samples, bins=50, density=True)\npyplot.plot(values[:], probabilities)\npyplot.show()\n\n\n\n\nThe KernelDensity class is powerful and does support estimating the PDF for multidimen- sional data.\nIn this tutorial, you discovered a gentle introduction to probability density estimation. Specifi- cally, you learned: * Histogram plots provide a fast and reliable way to visualize the probability density of a data sample. * Parametric probability density estimation involves selecting a common distribution and estimating the parameters for the density function from a data sample. * Nonparametric probability density estimation involves using a technique to fit a model to the arbitrary distribution of the data, like kernel density estimation."
  },
  {
    "objectID": "02-probability/02-foundations.html",
    "href": "02-probability/02-foundations.html",
    "title": "Joint, Marginal, and Conditional Probability",
    "section": "",
    "text": "Joint probability is the probability of two or more events occurring simultaneously.\nMarginal probability is the probability of an event irrespective of the outcome of other variables.\nConditional probability is the probability of one event occurring in the presence of one or more other events."
  },
  {
    "objectID": "02-probability/02-foundations.html#probability-for-one-random-variable",
    "href": "02-probability/02-foundations.html#probability-for-one-random-variable",
    "title": "Joint, Marginal, and Conditional Probability",
    "section": "Probability for One Random Variable",
    "text": "Probability for One Random Variable"
  },
  {
    "objectID": "02-probability/02-foundations.html#probability-for-multiple-random-variables",
    "href": "02-probability/02-foundations.html#probability-for-multiple-random-variables",
    "title": "Joint, Marginal, and Conditional Probability",
    "section": "Probability for Multiple Random Variables",
    "text": "Probability for Multiple Random Variables\nIn machine learning, we are likely to work with many random variables. For example, given a table of data, such as in excel, each row represents a separate observation or event, and each column represents a separate random variable. Variables may be either discrete, meaning that they take on a finite set of values, or continuous, meaning they take on a real or numerical value. As such, we are interested in the probability across two or more random variables.\nThis is complicated as there are many ways that random variables can interact, which, in turn, impacts their probabilities. This can be simplified by reducing the discussion to just two random variables (X, Y ), although the principles generalize to multiple variables\nTherefore, we will introduce the probability of multiple random variables as the probability of event A and event B, which in shorthand is X = A and Y = B. We assume that the two variables are related or dependent in some way. As such, there are three main types of probability we might want to consider; they are: * Joint Probability: Probability of events A and B. * Marginal Probability: Probability of event A given variable Y . * Conditional Probability: Probability of event A given event B.\nThese types of probability form the basis of much of predictive modeling with problems such as classification and regression. For example: * The probability of a row of data is the joint probability across each input variable. * The probability of a specific value of one input variable is the marginal probability across the values of the other input variables. * The predictive model itself is an estimate of the conditional probability of an output given an input example.\n\nJoint Probability for Two Variables\nWe may be interested in the probability of two simultaneous events, e.g. the outcomes of two different random variables. The probability of two (or more) events is called the joint probability. The joint probability of two or more random variables is referred to as the joint probability distribution. For example, the joint probability of event A and event B is written formally as: P (A and B) = P (A ∩ B) = P (A, B)\nThe joint probability for events A and B is calculated as the probability of event A given event B multiplied by the probability of event B. This can be stated formally as follows:\nP (A ∩ B) = P (A given B) × P (B)\nThe calculation of the joint probability is sometimes called the fundamental rule of probability or the product rule of probability. Here, P (A given B) is the probability of event A given that event B has occurred, called the conditional probability, described below. The joint probability is symmetrical, meaning that P (A ∩ B) is the same as P (B ∩ A).\n\n\nMarginal Probability\nWe may be interested in the probability of an event for one random variable, irrespective of the outcome of another random variable. For example, the probability of X = A for all outcomes of Y . The probability of one event in the presence of all (or a subset of) outcomes of the other random variable is called the marginal probability or the marginal distribution. The marginal probability of one random variable in the presence of additional random variables is referred to as the marginal probability distribution.\nP (X = A) = y∈YX P (X = A, Y = y)\nThis is another important foundational rule in probability, referred to as the sum rule. The marginal probability is different from the conditional probability (described next) because it considers the union of all events for the second variable rather than the probability of a single event.\n\n\nConditional Probability\nWe may be interested in the probability of an event given the occurrence of another event. The probability of one event given the occurrence of another event is called the conditional probability. The conditional probability of one to one or more random variables is referred to as the conditional probability distribution. For example, the conditional probability of event A given event B is written formally as:\nP (A given B) = P (A|B)\nThe conditional probability for events A given event B is calculated as follows: P (A|B) = P (A ∩ B) / P (B)"
  },
  {
    "objectID": "02-probability/02-foundations.html#probability-for-independence-and-exclusivity",
    "href": "02-probability/02-foundations.html#probability-for-independence-and-exclusivity",
    "title": "Joint, Marginal, and Conditional Probability",
    "section": "Probability for Independence and Exclusivity",
    "text": "Probability for Independence and Exclusivity\nWhen considering multiple random variables, it is possible that they do not interact. We may know or assume that two variables are not dependent upon each other instead are independent. Alternately, the variables may interact but their events may not occur simultaneously, referred to as exclusivity.\n\nIndependence\nIf one variable is not dependent on a second variable, this is called independence or statistical independence. This has an impact on calculating the probabilities of the two variables. For example, we may be interested in the joint probability of independent events A and B, which is the same as the probability of A and the probability of B. Probabilities are combined using multiplication, therefore the joint probability of independent events is calculated as the probability of event A multiplied by the probability of event B. This can be stated formally as follows: Joint Probability : P (A ∩ B) = P (A) × P (B)\nAs we might intuit, the marginal probability for an event for an independent random variable is simply the probability of the event. It is the idea of probability of a single random variable that are familiar with:\nMarginal Probability : P (A)\nWe refer to the marginal probability of an independent probability as simply the probability.\nSimilarly, the conditional probability of A given B when the variables are independent is simply the probability of A as the probability of B has no effect. For example:\nConditional Probability : P (A|B) = P (A)\nWe may be familiar with the notion of statistical independence from sampling. This assumes that one sample is unaffected by prior samples and does not affect future samples. Many machine learning algorithms assume that samples from a domain are independent to each other and come from the same probability distribution, referred to as independent and identically distributed, or i.i.d. for short.\n\n\nExclusivity\nIf the occurrence of one event excludes the occurrence of other events, then the events are said to be mutually exclusive. The probability of the events are said to be disjoint, meaning that they cannot interact, are strictly independent. If the probability of event A is mutually exclusive with event B, then the joint probability of event A and event B is zero. P (A ∩ B) = 0.0\nInstead, the probability of an outcome can be described as event A or event B, stated formally as follows:\nP (A or B) = P (A ∪ B) = P (A) + P (B)\nIf the events are not mutually exclusive, we may be interested in the outcome of either event. The probability of non-mutually exclusive events is calculated as the probability of event A and the probability of event B minus the probability of both events occurring simultaneously. This can be stated formally as follows:\nP (A ∪ B) = P (A) + P (B) − P (A ∩ B)"
  },
  {
    "objectID": "02-probability/01-intro.html",
    "href": "02-probability/01-intro.html",
    "title": "Introduction",
    "section": "",
    "text": "What is Probability?\nUncertainty involves making decisions with incomplete information, and this is the way we generally operate in the world. Handling uncertainty is typically described using everyday words like chance, luck, and risk. Probability is a field of mathematics that gives us the language and tools to quantify the uncertainty of events and reason in a principled manner.\nProbability theory is the mathematics of uncertainty. Uncertainty refers to imperfect or incomplete information. The world is messy and imperfect and we must make decisions and operate in the face of this uncertainty.For example, we often talk about luck, chance, odds, likelihood, and risk. These are words that we use to interpret and negotiate uncertainty in the world. When making inferences and reasoning in an uncertain world, we need principled, formal methods to express and solve problems. Probability provides the language and tools to handle uncertainty.\nThe probability, or likelihood, of an event is also commonly referred to as the odds of the event or the chance of the event. These all generally refer to the same notion, although odds often has its own notation of wins to losses, written as w:1; e.g. 1:3 for a 1 win and 3 losses or 1/4 (25%) probability of a win.\nProbability theory has three important concepts: * Event (A): An outcome to which a probability is assigned. * Sample Space (S): The set of possible outcomes or events. * Probability Function (P): The function used to assign a probability to an event\nThe likelihood of an event (A) being drawn from the sample space (S) is determined by the probability function (P ). The shape or distribution of all events in the sample space is called the probability distribution. Many domains have a familiar shape to the distribution of probabilities to events, such as uniform if all events are equally likely or Gaussian if the likelihood of the events forms a normal or bell-shape.\nTwo Schools of Probability\nThere are two main ways of interpreting or thinking about probability. The perhaps simpler approach is to consider probability as the actual likelihood of an event, called the Frequentist probability. Another approach is to consider probability a notion of how strongly it is believed the event will occur, called Bayesian probability. It is not that one approach is correct and the other is incorrect; instead, they are complementary and both interpretations provide different and useful techniques.\nFrequentist Probability\nThe frequentist approach to probability is objective. Events are observed and counted, and their frequencies provide the basis for directly calculating a probability, hence the name frequentist. Probability theory was originally developed to analyze the frequencies of events.\nMethods from frequentist probability include p-values and confidence intervals used in statistical inference and maximum likelihood estimation for parameter estimation.\nBayesian Probability\nThe Bayesian approach to probability is subjective. Probabilities are assigned to events based on evidence and personal belief and are centered around Bayes’ theorem, hence the name Bayesian. This allows probabilities to be assigned to very infrequent events and events that have not been observed before, unlike frequentist probability.\nOne big advantage of the Bayesian interpretation is that it can be used to model our uncertainty about events that do not have long term frequencies.\nMethods from Bayesian probability include Bayes factors and credible interval for inference and Bayes estimator and maximum a posteriori estimation for parameter estimation."
  },
  {
    "objectID": "02-probability/01-intro.html#uncertainty-in-machine-learning",
    "href": "02-probability/01-intro.html#uncertainty-in-machine-learning",
    "title": "Introduction",
    "section": "Uncertainty in Machine Learning",
    "text": "Uncertainty in Machine Learning\nThere are many sources of uncertainty in a machine learning project, including variance in the specific data values, the sample of data collected from the domain, and in the imperfect nature of any models developed from such data.\nNoise in data, incomplete coverage of the domain, and imperfect models provide the three main sources of uncertainty in machine learning.\nApplied machine learning requires getting comfortable with uncertainty. Uncertainty means working with imperfect or incomplete information.For software engineers and developers, computers are deterministic. You write a program, and the computer does what you say. Algorithms are analyzed based on space or time complexity and can be chosen to optimize whichever is most important to the project, like execution speed or memory constraints.\nThere are three main sources of uncertainty in machine learning:\nNoise in Observations\nAn observation from the domain is often referred to as an instance or a example and is one row of data. It is what was measured or what was collected. It is the data that describes the object or subject. It is the input to a model and the expected output.\nNoise refers to variability in the observation. Variability could be natural, such as a larger or smaller flower than normal. It could also be an error, such as a slip when measuring or a typo when writing it down. This variability impacts not just the inputs or measurements but also the outputs; for example, an observation could have an incorrect class label. This means that although we have observations for the domain, we must expect some variability or randomness.\nIncomplete Coverage of the Domain\nObservations from a domain used to train a model are a sample and incomplete by definition. In statistics, a random sample refers to a collection of observations chosen from the domain without systematic bias (e.g. uniformly random). Nevertheless, there will always be some limitation that will introduce bias. For example, we might choose to measure the size of randomly selected flowers in one garden. The flowers are randomly selected, but the scope is limited to one garden. Scope can be increased to gardens in one city, across a country, across a continent, and so on.\nAn appropriate level of variance and bias in the sample is required such that the sample is representative of the task or project for which the data or model will be used. We aim to collect or obtain a suitably representative random sample of observations to train and evaluate a machine learning model. Often, we have little control over the sampling process. Instead, we access a database or CSV file and the data we have is the data we must work with. In all cases, we will never have all of the observations. If we did, a predictive model would not be required. This means that there will always be some unobserved cases. There will be part of the problem domain for which we do not have coverage.\nThis is why we split a dataset into train and test sets or use resampling methods like k-fold cross-validation. We do this to handle the uncertainty in the representativeness of our dataset and estimate the performance of a modeling procedure on data not used in that procedure.\nImperfect Model of the Problem\nA machine learning model will always have some error. This is often summarized as all models are wrong, or more completely in an aphorism by George Box: All models are wrong but some are useful.\nThis does not apply just to the model, the artifact, but the whole procedure used to prepare it, including the choice and preparation of data, choice of training hyperparameters, and the interpretation of model predictions. Model error could mean imperfect predictions, such as predicting a quantity in a regression problem that is quite different to what was expected, or predicting a class label that does not match what would be expected. This type of error in prediction is expected given the uncertainty we have about the data that we have just discussed, both in terms of noise in the observations and incomplete coverage of the domain.\nAnother type of error is an error of omission. We leave out details or abstract them in order to generalize to new cases. This is achieved by selecting models that are simpler but more robust to the specifics of the data, as opposed to complex models that may be highly specialized to the training data. As such, we might and often do choose a model known to make errors on the training dataset with the expectation that the model will generalize better to new cases and have better overall performance.\nHow to Manage Uncertainty\nIn terms of noisy observations, probability and statistics help us to understand and quantify the expected value and variability of variables in our observations from the domain.\nIn terms of the incomplete coverage of the domain, probability helps to understand and quantify the expected distribution and density of observations in the domain.\nIn terms of model error, probability helps to understand and quantify the expected capability and variance in performance of our predictive models when applied to new data.\nBut this is just the beginning, as probability provides the foundation for the iterative training of many machine learning models, called maximum likelihood estimation, behind models such as linear regression, logistic regression, artificial neural networks, and much more. Probability also provides the basis for developing specific algorithms, such as Naive Bayes, as well as entire subfields of study in machine learning, such as graphical models like the Bayesian Belief Network."
  },
  {
    "objectID": "02-probability/01-intro.html#why-learn-probability-for-machine-learning",
    "href": "02-probability/01-intro.html#why-learn-probability-for-machine-learning",
    "title": "Introduction",
    "section": "Why Learn Probability for Machine Learning",
    "text": "Why Learn Probability for Machine Learning\n\nClass Membership Requires Predicting a Probability\nSome Algorithms Are Designed Using Probability\n\nNaive Bayes which is constructed using Bayes Theorem with some simplifying assumptions.\nProbabilistic Graphical Models (PGM) are designed around Bayes Theorem.\nBayesian Belief Networks or Bayes Nets, which are capable of capturing the conditional dependencies between variables.\n\nModels Are Trained Using a Probabilistic Framework\n\nMany machine learning models are trained using an iterative algorithm designed under a probabilistic framework. Perhaps the most common is the framework of maximum likelihood estimation, sometimes shorted as MLE. This is a framework for estimating model parameters (e.g. weights) given observed data. This is the framework that underlies the ordinary least squares estimate of a linear regression model. The expectation-maximization algorithm, or EM for short, is an approach for maximum likelihood estimation often used for unsupervised data clustering, e.g. estimating k means for k clusters, also known as the k-Means clustering algorithm.\nFor models that predict class membership, maximum likelihood estimation provides the framework for minimizing the difference or divergence between an observed and a predicted probability distribution. This is used in classification algorithms like logistic regression as well as deep learning neural networks. It is common to measure this difference in probability distributions during training using entropy, e.g. via cross-entropy. Entropy, differences between distributions measured via KL divergence, and cross-entropy are from the field of information theory that directly builds upon probability theory. For example, entropy is calculated directly as the negative log of the probability.\n\nModels Can Be Tuned With a Probabilistic Framework\nProbabilistic Measures Are Used to Evaluate Model Skill"
  },
  {
    "objectID": "04-calculus/calculus.html",
    "href": "04-calculus/calculus.html",
    "title": "Calculus and Optimization",
    "section": "",
    "text": "Much of machine learning is about minimizing a cost function (also called an objective function in the optimization community), which is a scalar function of several variables that typically measures how poorly our model fits the data we have."
  },
  {
    "objectID": "04-calculus/calculus.html#extrema",
    "href": "04-calculus/calculus.html#extrema",
    "title": "Calculus and Optimization",
    "section": "Extrema",
    "text": "Extrema\nOptimization is about finding extrema, which depending on the application could be minima or maxima.\nObserve that maximizing a function f is equivalent to minimizing −f , so optimization problems are typically phrased in terms of minimization without loss of generality. This convention (which we follow here) eliminates the need to discuss minimization and maximization separately.\nlocal minimum, local maximum, global minimum"
  },
  {
    "objectID": "04-calculus/calculus.html#gradients",
    "href": "04-calculus/calculus.html#gradients",
    "title": "Calculus and Optimization",
    "section": "Gradients",
    "text": "Gradients"
  },
  {
    "objectID": "04-calculus/calculus.html#the-jacobian",
    "href": "04-calculus/calculus.html#the-jacobian",
    "title": "Calculus and Optimization",
    "section": "The Jacobian",
    "text": "The Jacobian"
  },
  {
    "objectID": "04-calculus/calculus.html#the-hessian",
    "href": "04-calculus/calculus.html#the-hessian",
    "title": "Calculus and Optimization",
    "section": "The Hessian",
    "text": "The Hessian"
  },
  {
    "objectID": "04-calculus/calculus.html#matrix-calculus",
    "href": "04-calculus/calculus.html#matrix-calculus",
    "title": "Calculus and Optimization",
    "section": "Matrix calculus",
    "text": "Matrix calculus"
  },
  {
    "objectID": "04-calculus/calculus.html#taylors-theorem",
    "href": "04-calculus/calculus.html#taylors-theorem",
    "title": "Calculus and Optimization",
    "section": "Taylor’s theorem",
    "text": "Taylor’s theorem"
  },
  {
    "objectID": "04-calculus/calculus.html#conditions-for-local-minima",
    "href": "04-calculus/calculus.html#conditions-for-local-minima",
    "title": "Calculus and Optimization",
    "section": "Conditions for local minima",
    "text": "Conditions for local minima"
  },
  {
    "objectID": "04-calculus/calculus.html#convexity",
    "href": "04-calculus/calculus.html#convexity",
    "title": "Calculus and Optimization",
    "section": "Convexity",
    "text": "Convexity"
  }
]